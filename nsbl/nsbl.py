# -*- coding: utf-8 -*-

import click
import copy
import pprint
import json
import shutil
import subprocess
import sys

import os
import yaml
from cookiecutter.main import cookiecutter
from frkl import CHILD_MARKER_NAME, DEFAULT_LEAF_NAME, DEFAULT_LEAFKEY_NAME, KEY_MOVE_MAP_NAME, OTHER_KEYS_NAME, \
    UrlAbbrevProcessor, EnsureUrlProcessor, EnsurePythonObjectProcessor, FrklProcessor, \
    IdProcessor, dict_merge
from frkl import Frkl, ConfigProcessor
from jinja2 import Environment, PackageLoader
from six import string_types

try:
    set
except NameError:
    from sets import Set as set

import logging

log = logging.getLogger("nsbl")

# stem key for inventory
ENVS_KEY = "envs"
# meta info for groups/hosts (contains for example 'hosts' for groups)
ENV_META_KEY = "meta"
# name of the group/host
ENV_NAME_KEY = "name"
# type of the environemnt (either group or host)
ENV_TYPE_KEY = "type"
# under meta key, lists hosts of a group
ENV_HOSTS_KEY = "hosts"
# under meta key, lists sub-groups of a group, or which groups a host is member is
ENV_GROUPS_KEY = "groups"
# vars for a host/group
VARS_KEY = "vars"
# tasks for a hosts/group, used to create playbooks
TASKS_KEY = "tasks"

# bootstrap frkl processor chain for creating the inventory hosts/groups lists
NSBL_INVENTORY_BOOTSTRAP_FORMAT = {
    CHILD_MARKER_NAME: ENVS_KEY,
    DEFAULT_LEAF_NAME: ENV_META_KEY,
    DEFAULT_LEAFKEY_NAME: ENV_NAME_KEY,
    OTHER_KEYS_NAME: [VARS_KEY, TASKS_KEY],
    KEY_MOVE_MAP_NAME: VARS_KEY
}
# bootstrap chain used for creating the inventory
NSBL_INVENTORY_BOOTSTRAP_CHAIN = [
    UrlAbbrevProcessor(), EnsureUrlProcessor(), EnsurePythonObjectProcessor(),
    FrklProcessor(NSBL_INVENTORY_BOOTSTRAP_FORMAT)]

TASK_DESC_DEFAULT_FILENAME = "task-descs.yml"

# meta infor for tasks (e.g. 'become')
TASKS_META_KEY = "meta"
# name of the task, can be internal or external role, or an ansible module
TASK_META_NAME_KEY = "name"
# name that the role has, used in the playbook, added automatically according to the type of task that is processed
ROLE_NAME_KEY = "role"
# the type of task
TASK_TYPE_KEY = "task-type"
# key to indicate whether a task/role should be executed with superuser privileges
TASK_BECOME_KEY = "become"
# key to tell nsbl which variable keys are valid if the type is ansible module. ansible modules don't like getting fed keys that are not related to them
TASK_ALLOWED_VARS_KEY = "allowed_vars"
# key to indicate which role dependencies should be added for the ansible environment to be created
TASK_ROLES_KEY = "task-roles"
TASK_DYN_ROLE_DETAILS = "task-dyn-role-details"
# key to indicate allowed keys for an ansible module
VAR_KEYS_KEY = "var_keys"
# name that gets used by ansible, either a module name, or a role name
TASK_NAME_KEY = "task-name"
# (optional) short description of the task
TASK_DESC_KEY = "task-desc"
# name to indicate to use the ansible 'with_items' directive
TASK_WITH_ITEMS_KEY = "with_items"
# id of the task within the task group
TASK_ID_KEY = "_task_id"
# id of the environment tasks are run in
ENV_ID_KEY = "_env_id"
# id of the task within a dynamic role
DYN_TASK_ID_KEY = "_dyn_task_id"
DEFAULT_KEY_KEY = "default-key"
SPLIT_KEY_KEY = "split-key"
WITH_ITEMS_KEY = "with_items"

# indicator for task type internal role
INT_TASK_TYPE = "internal_role"
# indicator for task type external role
EXT_TASK_TYPE = "external_role"
# indicator for task type ansible module
DYN_TASK_TYPE = "single_task"
# indicator for task type autogenerated dynamic role (out of DYN_TASK_TYPEs)
DYN_ROLE_TYPE = "dynamic_role"
# filename that contains meta information for internal roles
ROLE_META_FILENAME = "meta.yml"

DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT = {
    CHILD_MARKER_NAME: TASKS_KEY,
    DEFAULT_LEAF_NAME: TASKS_META_KEY,
    DEFAULT_LEAFKEY_NAME: TASK_META_NAME_KEY,
    KEY_MOVE_MAP_NAME: {'*': (VARS_KEY, 'default')},
    "use_context": True
}

def generate_nsbl_tasks_format(task_descs):

    result = copy.deepcopy(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT)

    for task_desc in task_descs:
        if DEFAULT_KEY_KEY in task_desc[TASKS_META_KEY].keys():
            result[KEY_MOVE_MAP_NAME][task_desc[TASKS_META_KEY][TASK_META_NAME_KEY]] = task_desc[TASKS_META_KEY][DEFAULT_KEY_KEY]

    return result

NSBL_TASKS_TEMPLATE_INIT = {
    "use_environment_vars": True,
    "use_context": True
}

ID_NAME = "id"
NSBL_TASKS_ID_INIT = {
    "id_key": TASKS_META_KEY,
    "id_name": ID_NAME
}

ENV_TYPE_HOST = 'host'
ENV_TYPE_GROUP = 'group'
DEFAULT_ENV_TYPE = ENV_TYPE_GROUP

# DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN = [
# UrlAbbrevProcessor(), EnsureUrlProcessor(), Jinja2TemplateProcessor(NSBL_TASKS_TEMPLATE_INIT), EnsurePythonObjectProcessor(), FrklProcessor(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT), IdProcessor(NSBL_TASKS_ID_INIT)
# ]

DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN = [
    FrklProcessor(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT)
]

# ------------------------------
# util functions
def get_pkg_mgr_sudo(mgr):
    """Simple function to determine whether a given package manager needs sudo rights or not.
    """
    if mgr == 'no_install':
        return False
    elif mgr == 'nix':
        return False
    elif mgr == 'conda':
        return False
    elif mgr == 'git':
        return False
    elif mgr == 'homebrew':
        return False
    else:
        return True

def get_git_auto_dest_name(repo, parent_dir="~"):

    temp = "{}{}{}".format(parent_dir, os.path.sep, repo.split("/")[-1])

    if temp.endswith(".git"):
        temp = temp[0:-4]

    return temp

def ensure_git_repo_format(repo, dest=None):

    if isinstance(repo, string_types):
        if dest:
            return {"repo": repo, "dest": dest}
        else:
            return {"repo": repo, "dest": get_git_auto_dest_name(repo)}
    elif isinstance(repo, dict):
        if "repo" not in repo.keys():
            raise NsblException("Repo dictionary needs at least a 'repo' key: {}".format(repo))
        if "dest" not in repo.keys():
            if dest:
                repo["dest"] = dest
            else:
                repo["dest"] = get_git_auto_dest_name(repo["repo"])
        return repo
    else:
        raise NsblException("Repo value needs to be either string or dict format: {}".format(repo))


def get_local_role_desc(role_name, role_repos=[]):

    url = False
    if os.path.exists(role_name):
        url = role_name
    else:
        for repo in role_repos:
            path = os.path.join(os.path.expanduser(repo), role_name)
            if os.path.exists(path):
                url = role_name

    if not url:
        raise NsblException("Can't find local role '{}' (neither as absolute path nor in any of the local role repos)".format(role_name))

    return {"url": url}

def merge_roles(role_obj, role_repos=[]):

    role_dict = {}

    if isinstance(role_obj, dict):
        if "url" in role_obj.keys() or "version" in role_obj.keys():
            raise NsblException("Although dictionaries and lists can be mixed for the {} key, dictionaries need to use role-names as keys, the keyworkds 'url' and 'version' are not allowed. Mostly likely this is a misconfiguration.")
        role_dict.update(role_obj)
    elif isinstance(role_obj, string_types):
        temp = get_local_role_desc(role_obj, role_repos)
        role_dict[role_obj] = temp
    elif isinstance(role_obj, (list, tuple)):
        for role_obj_child in role_obj:
            temp = merge_roles(role_obj_child, role_repos)
            role_dict.update(temp)
    else:
        raise NsblException("Role description needs to be either a list of strings or a dict. Value '{}' is not valid.".format(role_obj))

    return role_dict

def expand_external_role(role_dict, role_repos=[]):

    temp_role_dict = merge_roles(role_dict, role_repos)

    result = {}
    for role_name, role_details in temp_role_dict.items():
        temp_role = {}
        if isinstance(role_details, string_types):
            temp_role["url"] = role_details
        elif isinstance(role_details, dict):
            temp_role["url"] = role_details["url"]
            if "version" in role_details.keys():
                temp_role["version"] = role_details["version"]
        result[role_name] = temp_role

    return result

def get_internal_role_path(role_dict, role_repos=[]):

    if isinstance(role_dict, string_types):
        url = role_dict
    elif isinstance(role_dict, dict):
        url = role_dict["url"]
    else:
        raise NsblException("Type '{}' not supported for role description: {}".format(type(role_dict), role_dict))

    if os.path.exists(url):
        return url

    for repo in role_repos:
        path = os.path.join(os.path.expanduser(repo), url)
        if os.path.exists(path):
            return path

    return False




class NsblException(Exception):
    """Base exception class for nsbl."""

    def __init__(self, message):
        super(NsblException, self).__init__(message)


class Nsbl(object):
    def __init__(self, configs, int_task_descs=None, role_repos=None, default_env_type=DEFAULT_ENV_TYPE, use_default_roles=True, use_repo_task_descs=True):
        """Wrapper class to create an Ansible environment.

        Args:
          configs (list): the configuration(s) describing the inventory and tasks
          int_tasks_descs (list): path(s)/urls to all local role repos
          default_env_type (str): the default type for an environment if not provided in the config (either ENV_TYPE_HOST or ENV_TYPE_GROUP)
          use_default_roles (bool): whether to use the default roles that come with nsbl
          use_repo_task_descs (bool): whether to use task descriptions that come with roles repos (filename: TASK_DESC_DEFAULT_FILENAME in repo root directory)
        """

        self.configs = configs

        if not role_repos:
            role_repos = []

        if isinstance(role_repos, string_types):
            self.role_repos = [role_repos]
        else:
            self.role_repos = role_repos

        default_roles_path = os.path.join(os.path.dirname(__file__), "external", "default-roles")

        if not self.role_repos:
            self.role_repos.append(default_roles_path)
        elif use_default_roles:
            self.role_repos.insert(0, default_roles_path)

        #TODO: check whether paths exist

        if isinstance(int_task_descs, string_types):
            int_task_descs = [int_task_descs]
        elif not isinstance(int_task_descs, (list, tuple)):
            raise Exception("task_descs needs to be string or list: '{}'".format(int_task_descs))

        if not int_task_descs:
            int_task_descs = []

        if use_repo_task_descs:
            repo_int_task_descs = []
            for repo in self.role_repos:
                task_desc_file = os.path.join(os.path.expanduser(repo), TASK_DESC_DEFAULT_FILENAME)
                if os.path.exists(task_desc_file):
                    repo_int_task_descs.append(task_desc_file)

            int_task_descs = repo_int_task_descs + int_task_descs

        #TODO: check whether paths exist

        frkl_format = generate_nsbl_tasks_format([])
        task_desk_frkl = Frkl(int_task_descs, [UrlAbbrevProcessor(),
                                               EnsureUrlProcessor(),
                                               EnsurePythonObjectProcessor(),
                                               FrklProcessor(frkl_format)])

        self.int_task_descs = task_desk_frkl.process()

        self.inventory = NsblInventory(self.configs, self.int_task_descs, self.role_repos, default_env_type)
        self.tasks = self.inventory.tasks

    def render_environment(self, env_dir, extract_vars=False, force=False, ansible_verbose=""):
        """Creates the ansible environment in the folder provided.

        Args:
          env_dir (str): the folder where the environment should be created
          extract_vars (bool): whether to extract a hostvars and groupvars directory for the inventory (True), or render a dynamic inventory script for the environment (default, False)
        """

        result = {}
        result['env_dir'] = env_dir
        if os.path.exists(env_dir) and force:
            shutil.rmtree(env_dir)

        all_ext_roles = {}
        all_int_roles = {}
        #TODO: check for duplicate and different roles
        for tasks in self.tasks:
            meta_roles = tasks.meta_roles
            for role_name, role_dict in meta_roles.items():
                role_path = get_internal_role_path(role_dict, self.role_repos)
                if role_path:
                    all_int_roles[role_name] = role_path
                else:
                    all_ext_roles[role_name] = role_dict
            for t in tasks.tasks:
                task_name = t[TASKS_META_KEY][TASK_NAME_KEY]
                local_role = get_internal_role_path(task_name, self.role_repos)
                if local_role:
                    all_int_roles[task_name] = local_role
                roles = t.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {})
                for role_name, role_dict in roles.items():
                    role_path = get_internal_role_path(role_dict, self.role_repos)
                    if role_path:
                        all_int_roles[role_name] = role_path
                    else:
                        all_ext_roles[role_name] = role_dict

        inventory_dir = os.path.join(env_dir, "inventory")
        result["inventory_dir"] = inventory_dir

        if extract_vars:
            inv_target = "../inventory/hosts"
        else:
            inv_target = "../inventory/inventory"

        result["extract_vars"] = extract_vars

        playbook_dir = os.path.join(env_dir, "plays")
        result["playbook_dir"] = playbook_dir

        ask_sudo = ""
        all_plays_name = "all_plays.yml"
        result["default_playbook_name"] = all_plays_name

        ansible_playbook_args = ansible_verbose
        result["ansible_playbook_args"] = ansible_playbook_args
        result["run_playbooks_script"] = os.path.join(env_dir, "run_all_plays.sh")

        cookiecutter_details = {
            "inventory": inv_target,
            "env_dir": env_dir,
            "playbook_dir": playbook_dir,
            "ansible_playbook_args": ansible_playbook_args,
            "library_path": "library",
            "action_plugins_path": "action_plugins",
            "extra_script_commands": "",
            "ask_sudo": ask_sudo,
            "playbook": all_plays_name,
            "nsbl_roles": all_ext_roles,
            "callback_plugins": "callback_plugins",
            "callback_plugin_name": ""
        }

        log.debug("Creating build environment from template...")
        log.debug("Using cookiecutter details: {}".format(cookiecutter_details))

        template_path = os.path.join(os.path.dirname(__file__), "external", "cookiecutter-ansible-environment")

        cookiecutter(template_path, extra_context=cookiecutter_details, no_input=True)

        if extract_vars:
            self.inventory.extract_vars(inventory_dir)

        self.inventory.write_inventory_file_or_script(inventory_dir, extract_vars=extract_vars)

        # copy extra_plugins
        library_path = os.path.join(os.path.dirname(__file__), "external", "extra_plugins", "library")
        action_plugins_path = os.path.join(os.path.dirname(__file__), "external", "extra_plugins", "action_plugins")
        callback_plugins_path = os.path.join(os.path.dirname(__file__), "external", "extra_plugins", "callback_plugins")
        result["library_path"] = library_path
        result["callback_plugins_pagh"] = callback_plugins_path
        result["action_plugins_path"] = action_plugins_path

        target_dir = os.path.join(env_dir, "plays")

        shutil.copytree(library_path, os.path.join(target_dir, "library"))
        shutil.copytree(action_plugins_path, os.path.join(target_dir, "action_plugins"))
        shutil.copytree(callback_plugins_path, os.path.join(target_dir, "callback_plugins"))

        # copy internal roles
        for role_name, role in all_int_roles.items():
            target = os.path.join(env_dir, "roles", "internal", role_name)
            shutil.copytree(role, target)

        all_dyn_roles = {}
        for tasks in self.tasks:
            for task in tasks.tasks:
                if task[TASKS_META_KEY][TASK_TYPE_KEY] == DYN_ROLE_TYPE:
                    all_dyn_roles[task[TASKS_META_KEY][TASK_NAME_KEY]] = task[TASKS_META_KEY][TASK_DYN_ROLE_DETAILS]

        # create dynamic roles
        for role_name, role_tasks in all_dyn_roles.items():
            role_local_path = os.path.join(os.path.dirname(__file__), "external", "ansible-role-template")
            # cookiecutter doesn't like input lists, so converting to dict
            tasks = {}

            for task in role_tasks:
                task_name = task[TASKS_META_KEY][DYN_TASK_ID_KEY]
                tasks[task_name] = task
                if VARS_KEY not in task.keys():
                    task[VARS_KEY] = {}
                if VAR_KEYS_KEY not in task[TASKS_META_KEY].keys() or task[TASKS_META_KEY][VAR_KEYS_KEY] == '*':
                    task[TASKS_META_KEY][VAR_KEYS_KEY] = list(task.get(VARS_KEY, {}).keys())
                else:
                    for key in task.get(VARS_KEY, {}).keys():
                        task[TASKS_META_KEY][VAR_KEYS_KEY].append(key)

                # make var_keys items unique
                task[TASKS_META_KEY][VAR_KEYS_KEY] = list(set(task[TASKS_META_KEY][VAR_KEYS_KEY]))
                if WITH_ITEMS_KEY in task[TASKS_META_KEY].keys():
                    with_items_key = task[TASKS_META_KEY][WITH_ITEMS_KEY]

                    # if with_items_key not in task[VARS_KEY]:
                        # raise NsblException("Can't iterate over variable '{}' using with_items because key does not exist in: {}".format(task[TASK_NAME_KEY][VARS_KEY]))

                    # task[TASKS_META_KEY][VARS_KEY] = "item"

            role_dict = {
                "role_name": role_name,
                "tasks": tasks,
                "dependencies": ""
            }

            current_dir = os.getcwd()
            int_roles_base_dir = os.path.join(env_dir, "roles", "dynamic")
            os.chdir(int_roles_base_dir)

            cookiecutter(role_local_path, extra_context=role_dict, no_input=True)
            os.chdir(current_dir)

        if all_ext_roles:
            # download external roles
            log.debug("Downloading and installing external roles...")
            res = subprocess.check_output([os.path.join(env_dir, "extensions", "setup", "role_update.sh")])
            for line in res.splitlines():
                log.debug("Installing role: {}".format(line.encode('utf8')))

        playbooks = []
        for idx, task in enumerate(self.tasks):
            jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
            template = jinja_env.get_template('playbook.yml')
            output_text = template.render(groups=task.env_name, tasks=task.tasks, env=task.env)

            playbook_name = "play_{}_{}.yml".format(idx, task.env_name)
            playbooks.append(playbook_name)
            playbook_file = os.path.join(env_dir, "plays", playbook_name)

            with open(playbook_file, "w") as text_file:
                text_file.write(output_text)

        template = jinja_env.get_template('play.yml')
        output_text = template.render(playbooks=playbooks)
        all_plays_file = os.path.join(env_dir, "plays", all_plays_name)

        with open(all_plays_file, "w") as text_file:
            text_file.write(output_text)

        result['lookup_dict'] = self.get_lookup_dict()
        return result

    def get_task(self, env_id, task_id, dyn_role_task_id=None):

        for task in self.tasks:
            if task.env_id != env_id:
                continue

            for int_tasks in task.tasks:

                if int_tasks[TASKS_META_KEY][TASK_ID_KEY] != task_id:
                    continue

                if dyn_role_task_id != None:
                    for t in  int_tasks[TASKS_META_KEY][TASK_DYN_ROLE_DETAILS]:
                        if t[TASKS_META_KEY][DYN_TASK_ID_KEY] == dyn_role_task_id:
                            return t
                else:
                    return int_tasks

        return None

    def get_lookup_dict(self):

        result = {}
        for task in self.tasks:

            id = task.env_id
            #id = task.env_name
            tasks_lookup_dict = task.get_lookup_dict()

            result[id] = tasks_lookup_dict

        return result


class NsblRunner(object):

    def __init__(self, nsbl):

        self.nsbl = nsbl

    def run(self, target, extract_vars, force=True, ansible_verbose=""):

        parameters = self.nsbl.render_environment(target, extract_vars=extract_vars, force=force, ansible_verbose=ansible_verbose )
        lookup_dict = parameters['lookup_dict']

        callback_adapter = NsblLogCallbackAdapter(lookup_dict)

        run_env = os.environ.copy()
        run_env['NSBL_ENVIRONMENT'] = "true"
        script = parameters['run_playbooks_script']
        proc = subprocess.Popen(script, stdout=subprocess.PIPE, stderr=sys.stdout.fileno(), stdin=subprocess.PIPE, shell=True, env=run_env)

        for line in iter(proc.stdout.readline, ''):
            callback_adapter.add_log_message(line)

        return


        # current_env_id = None
        # current_task_id = None
        # current_dyn_task_id = None
        # current_task = None
        # current_task_output = []
        # nsbl_item_details = False
        # task_item_details = False


        #     details = json.loads(line)
        #     category = details['category']

        #     # print(line)

        #     if not category.startswith("nsbl"):

        #         env_id = details[ENV_ID_KEY]
        #         task_id = details[TASK_ID_KEY]

        #         if env_id == None or task_id == None:
        #             continue

        #         task_changed = False
        #         if env_id != current_env_id:
        #             task_changed = True

        #         if current_task_id != task_id:
        #             task_changed = True

        #         dyn_task_id = details.get(DYN_TASK_ID_KEY, None)

        #         if dyn_task_id != None and current_dyn_task_id != dyn_task_id:
        #             task_changed = True

        #         if task_changed:
        #             if current_env_id != None:
        #                 self.process_task_finished(current_task_output, nsbl_item_details, task_item_details, current_env_id, current_task_id, current_dyn_task_id)
        #             current_env_id = env_id
        #             current_task_id = task_id
        #             current_dyn_task_id = dyn_task_id
        #             nsbl_item_details = False
        #             task_item_details = False

        #             if current_dyn_task_id == None:
        #                 current_task = lookup_dict[current_env_id][current_task_id]
        #             else:
        #                 current_task = lookup_dict[current_env_id][current_task_id][current_dyn_task_id]

        #         item = details.get('item', None)
        #         task_desc = current_task[TASK_DESC_KEY]

        #         msg = details.get("result", {}).get("msg", None)
        #         if category == "task_start":
        #             if task_changed:
        #                 msg = " * {}...".format(task_desc)
        #                 click.echo(msg)
        #         elif category == "failed":
        #             if details.get("ignore_errors", False):
        #                 continue
        #             else:
        #                 msg = "        => failed: {}".format(msg)
        #                 click.echo(msg)
        #         elif category == "item_ok":
        #             task_item_details = True
        #             if not nsbl_item_details:
        #                 msg = "    - {} =>\tok".format(details["item"])
        #                 click.echo(msg)
        #         elif category == "task_ok":
        #             # if not nsbl_item_details and not task_item_details:
        #             current_task_output.append(details)
        #         elif category == "skipped":
        #             current_task_output.append(details)


        #         # print("env: {}, task: {}, dyn_task: {}".format(current_env_id, current_task_id, current_dyn_task_id))
        #     else:
        #         if current_env_id == None or current_task_id == None:
        #             raise Exception("Item information before task information. This is a bug, needs fixing. Please contact developer.")
        #         nsbl_item_details = True
        #         if category == "nsbl_item_started":
        #             msg = "    - {} =>".format(details["item"])
        #         elif category == "nsbl_item_ok":
        #             msg = "\tok\n"
        #         elif category == "nsbl_item_failed":
        #             msg = "\tfailed: {}\n".format(details["msg"])

        #         click.echo(msg, nl=False)

        # if current_task_output:
        #     self.process_task_finished(current_task_output, nsbl_item_details, task_item_details, current_task_id, current_dyn_task_id)


    def process_task_finished(self, current_task_output, nsbl_item_details, task_item_details, current_env_id, current_task_id, current_dyn_task_id=None):

        # we don't need to print out anything if item_details are used as it is done while the item is being processed
        # which makes for a nicer user experience
        if not nsbl_item_details:
            if current_task_output:
                self.process_task_output(current_task_output)

        del current_task_output[:]

    def process_task_output(self, task_output):

        non_skipped = False
        changed = False
        for t in task_output:
            if  t['result']['changed']:
                changed = True
            if t['category'] != 'skipped':
                non_skipped = True

        if not changed:
            click.echo("        => no change")
        elif non_skipped:
            click.echo("        => ok")
        else:
            # will probably never apply...
            click.echo("        => skipped")

class NsblLogCallbackAdapter(object):

    def __init__(self, lookup_dict):

        self.lookup_dict = lookup_dict
        self.current_env_id = None
        self.current_task_id = None
        self.current_dyn_task_id = None
        self.current_task_is_dyn_role = False
        self.current_task = None

        self.current_task_started = False
        self.current_task_has_nsbl_items = False
        self.current_task_has_items = False

        self.current_task_saved_events = []

    def add_log_message(self, line):

        details = json.loads(line)

        category = details["category"]

        if not category.startswith("nsbl"):
            env_id = details[ENV_ID_KEY]
            task_id = details[TASK_ID_KEY]
            if env_id == None or task_id == None:
                return

            task_changed = False
            if env_id != self.current_env_id:
                task_changed = True

            if task_id != self.current_task_id:
                task_changed = True

            dyn_task_id = details.get(DYN_TASK_ID_KEY, None)
            if dyn_task_id != None and self.current_dyn_task_id != dyn_task_id:
                task_changed = True
                self.current_task_is_dyn_role = True

            if task_changed:
                if self.current_env_id != None:
                    self.process_task_changed()

                self.current_env_id = env_id
                self.current_task_id = task_id
                self.current_dyn_task_id = dyn_task_id
                self.nsbl_item_details = False
                self.task_item_details = False

                if self.current_dyn_task_id == None:
                    self.current_task = self.lookup_dict[self.current_env_id][self.current_task_id]
                else:
                    self.current_task = self.lookup_dict[self.current_env_id][self.current_task_id][self.current_dyn_task_id]

            task_desc = self.current_task[TASK_DESC_KEY]
            task_name = self.current_task[TASK_NAME_KEY]
        else:
            task_desc = None
            task_name = None

        msg = details.get('msg', None)
        item = details.get('item', None)
        status = details.get('status', None)
        skipped = details.get('skipped', None)
        self.add_event(category, task_name, task_desc, status, item, msg, skipped)

    def add_event(self, category, task_name, task_desc, status, item, msg, skipped):

        output = None
        # print("           ....{}".format(category))
        if category.startswith("nsbl"):
            if category == "nsbl_item_started":
                self.current_task_has_nsbl_items = True
                output = "    - {} =>".format(item)
            elif category == "nsbl_item_ok":
                output = "\tok\n"
            elif category == "nsbl_item_failed":
                output = "\tfailed: {}\n".format(msg)
        else:
            event = {"category": category, "task_name": task_name, "task_desc":task_desc, "status": status, "item": item, "msg": msg, "skipped": skipped}
            if category == "task_start":
                if not self.current_task_started:
                    self.current_task_started = True
                    output = " * {}...\n".format(task_desc)
                else:
                    self.current_task_saved_events.append(event)
            elif category == "item_ok":
                # print(self.current_task_has_nsbl_items)
                self.current_task_has_items = True
                if not self.current_task_has_nsbl_items:
                    output = "    - {} =>\tok\n".format(item)
            elif category == "item_failed":
                if not self.current_task_has_nsbl_items:
                    output = "    - {} =>\tfailed: {}\n".format(item, msg)
            elif category == "failed":
                if not self.current_task_has_nsbl_items and not self.current_task_has_items:
                    self.current_task_saved_events.append(event)
            elif category == "ok":
                if not self.current_task_has_nsbl_items and not self.current_task_has_items:
                    self.current_task_saved_events.append(event)

        if output:
            click.echo(output, nl=False)

    def process_task_changed(self):

        print("TASK_CHANGED: {}".format(self.current_task_saved_events))
        self.current_task_started = False
        self.current_task_has_nsbl_items = False
        self.current_task_has_items = False
        self.current_task_is_dyn_role = False
        self.current_task_saved_events = []

class NsblInventory(object):

    def __init__(self, configs, int_task_descs=[], role_repos=[], default_env_type=DEFAULT_ENV_TYPE):
        """Class to be used to create a dynamic ansible inventory from (elastic) yaml config files.

        Args:
          configs (list): list of paths to inventory config (elastic) yaml files
          int_task_descs (list): descriptions of internal tasks (used to 'expand' task name keywords)
          default_env_type (str): the default type for an environment if not provided in the config (either ENV_TYPE_HOST or ENV_TYPE_GROUP)
        """

        self.configs = configs
        self.frkl_obj = Frkl(configs, NSBL_INVENTORY_BOOTSTRAP_CHAIN)
        self.config = self.frkl_obj.process()
        self.default_env_type = default_env_type
        self.int_task_deskcs = int_task_descs
        self.role_repos = role_repos
        self.groups = {}
        self.hosts = {}
        self.tasks = []

        self.assemble_groups()

    def extract_vars(self, inventory_dir):

        for group, group_vars in self.groups.items():
            vars = group_vars.get(VARS_KEY, {})
            if not vars:
                continue
            group_dir = os.path.join(inventory_dir, "group_vars", group)
            var_file = os.path.join(group_dir, "{}.yml".format(group))
            content = yaml.dump(vars, default_flow_style=False)

            os.makedirs(group_dir)
            with open(var_file, "w") as text_file:
                text_file.write(content)

        for host, host_vars in self.hosts.items():
            vars = host_vars.get(VARS_KEY, {})
            if not vars:
                continue
            host_dir = os.path.join(inventory_dir, "host_vars", host)
            var_file = os.path.join(host_dir, "{}.yml".format(host))
            content = yaml.dump(vars, default_flow_style=False)

            os.makedirs(host_dir)
            with open(var_file, "w") as text_file:
                text_file.write(content)

    def get_inventory_config_string(self):

        jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
        template = jinja_env.get_template('hosts')
        output_text = template.render(groups=self.groups, hosts=self.hosts)

        return output_text

    def write_inventory_file_or_script(self, inventory_dir, extract_vars=False, relative_paths=True):

        if extract_vars:
            inventory_string = self.get_inventory_config_string()
            inventory_name = "hosts"
            inventory_file = os.path.join(inventory_dir, inventory_name)

            with open(inventory_file, "w") as text_file:
                text_file.write(inventory_string)

        else:
            # write dynamic inventory script
            jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
            if relative_paths:
                template = jinja_env.get_template('inventory_relative')
            else:
                template = jinja_env.get_template('inventory_absolute')

            roles_repos_string = ""
            if self.roles_repo_folders:
                if relative_paths:
                    roles_repos_string = " --repo ".join(
                        [os.path.relpath(name, inventory_dir) for name in self.roles_repo_folders])

                    rel_configs = []

                    for path in self.configs:
                        rel_path = os.path.relpath(path, inventory_dir)
                        rel_configs.append(rel_path)

                    script_configs = " --config ".join(rel_configs)
                else:
                    roles_repos_string = " --repo ".join([os.path.abspath(name) for name in self.roles_repos])

                    abs_configs = []
                    for path in self.configs:
                        abs_path = os.path.abspath(path)
                        abs_configs.append(abs_path)
                    script_configs = " --config".join(abs_configs)

            output_text = template.render(role_repo_paths=roles_repos_string, nsbl_script_configs=script_configs)

            inventory_string = self.get_inventory_config_string()
            inventory_target_name = "inventory"

            inventory_file = os.path.join(inventory_dir, inventory_target_name)

            with open(inventory_file, "w") as text_file:
                text_file.write(output_text)

            st = os.stat(inventory_file)
            os.chmod(inventory_file, 0o775)

    def add_group(self, group_name, group_vars):
        """Add a group to the dynamic inventory.

        Args:
          group_name (str): the name of the group
          group_vars (dict): the variables for this group
        """

        if group_name in self.groups.keys():
            raise NsblException("Group '{}' defined twice".format(group_name))

        self.groups[group_name] = {}
        self.groups[group_name]["vars"] = group_vars
        self.groups[group_name]["hosts"] = []
        self.groups[group_name]["children"] = []

    def add_host(self, host_name, host_vars):
        """Add a host to the dynamic inventory.

        Args:
          host_name (str): the name of the host
          host_vars (dict): the variables for this host
        """

        if host_name not in self.hosts.keys():
            self.hosts[host_name] = {VARS_KEY: {}}

        if not host_vars:
            return

        intersection = set(self.hosts[host_name].get(VARS_KEY, {}).keys()).intersection(host_vars.keys())

        if intersection:
            raise NsblException(
                "Adding host more than once with intersecting keys, this is not possible because it's not clear which vars should take precedence. Intersection: {}".format(
                    intersection))

        self.hosts[host_name][VARS_KEY].update(host_vars)

    def add_group_to_group(self, child, group):
        """Adds a group as a subgroup of another group.

        Args:
          child (str): the name of the sub-group
          group (str): the name of the parent group
        """

        if group not in self.groups[group]["children"]:
            self.groups[group]["children"].append(child)

    def add_host_to_group(self, host, group):
        """Adds a host to a group.

        Args:
          host (str): the name of the host
          group (str): the name of the parent group
        """

        if host not in self.groups[group]["hosts"]:
            self.groups[group]["hosts"].append(host)

        self.add_host(host, None)

    def assemble_groups(self):
        """Kicks of the processing of the config files."""

        env_id = 0
        for env in self.config:
            if ENV_META_KEY not in env.keys():
                raise NsblException(
                    "Environment does not have metadata (missing '{}') key: {})".format(ENV_META_KEY, env))
            env_type = env[ENV_META_KEY].get(ENV_TYPE_KEY, False)
            if not env_type:
                if ENV_HOSTS_KEY in env[ENV_META_KEY].keys():
                    env_type = ENV_TYPE_GROUP
                elif ENV_GROUPS_KEY in env[ENV_META_KEY].keys():
                    env_type = ENV_TYPE_HOST
                else:
                    env_type = self.default_env_type

            env_name = env[ENV_META_KEY].get(ENV_NAME_KEY, False)
            if not env_name:
                raise NsblException(
                    "Environment metadata needs to contain a name (either host- or group-name): {}".format(
                        env[ENV_META_KEY]))

            if env_type == ENV_TYPE_HOST:

                self.add_host(env_name, env.get(VARS_KEY, {}))

                if ENV_HOSTS_KEY in env.get(ENV_META_KEY, {}).keys():
                    raise NsblException(
                        "An environment of type {} can't contain the {} key".format(ENV_TYPE_HOST, ENV_HOSTS_KEY))

                for group in env[ENV_META_KEY].get(ENV_GROUPS_KEY, []):
                    self.add_host_to_group(env_name, group)

            elif env_type == ENV_TYPE_GROUP:

                self.add_group(env_name, env.get(VARS_KEY, {}))

                for host in env[ENV_META_KEY].get(ENV_HOSTS_KEY, []):
                    self.add_host_to_group(host, env_name)

                for group in env[ENV_META_KEY].get(ENV_GROUPS_KEY, []):
                    self.add_group_to_group(group, env_name)

            else:
                raise NsblException("Environment type needs to be either 'host' or 'group': {}".format(env_type))

            if TASKS_KEY in env.keys():
                self.tasks.append(NsblTasks(env, env_id, self.int_task_deskcs, self.role_repos, env_name))
                env_id += 1

        if "localhost" in self.hosts.keys() and "ansible_connection" not in self.hosts["localhost"].get(VARS_KEY,
                                                                                                        {}).keys():
            self.hosts["localhost"][VARS_KEY]["ansible_connection"] = "local"


    def list(self):
        """Lists all groups in the format that is required for ansible dynamic inventories.

        More info: https://docs.ansible.com/ansible/intro_dynamic_inventory.html, http://docs.ansible.com/ansible/dev_guide/developing_inventory.html

        Returns:
        dict: a dict containing all information about all hosts/groups
        """

        result = copy.copy(self.groups)
        result["_meta"] = {"hostvars": self.hosts}

        return json.dumps(result, sort_keys=4, indent=4)

    def host(self, host):
        """Returns the inventory information for the specified host, in the format required for ansible dynamic inventories.

        Args:
          host (str): the name of the host
        Returns:
        dict: all inventory information for this host
        """

        host_vars = self.hosts.get(host, {}).get(VARS_KEY, {})
        return json.dumps(host_vars, sort_keys=4, indent=4)

    def get_vars(self, env_name):
        """Returns all variables for the environment with the specified name.

        First tries whether the name matches a group, then tries hosts.

        Args:
          env_name (str): the name of the group or host
        Returns:
          dict: the variables for the environment
        """

        if env_name in self.groups.keys():
            return self.groups[env_name].get(VARS_KEY, {})
        elif env_name in self.hosts.keys():
            return self.hosts[env_name].get(VARS_KEY, {})
        else:
            raise NsblException("Neither group or host with name '{}' exists".format(env_name))

class NsblTaskProcessor(ConfigProcessor):
    """Processor to take a list of (unfrklized) tasks, and frklizes (expands) the data.

    In particular, this extracts roles and tags them with their types.
    """

    def validate_init(self):

        self.task_name_key = [TASKS_META_KEY, TASK_META_NAME_KEY]
        self.meta_roles = self.init_params['meta_roles']
        self.task_descs = self.init_params.get('task_descs', [])
        self.role_repos = self.init_params.get('role_repos', [])
        return True

    def process_current_config(self):

        new_config = self.current_input_config
        meta_task_name = new_config[TASKS_META_KEY][TASK_META_NAME_KEY]

        for task_desc in self.task_descs:
            task_desc_name = task_desc.get(TASKS_META_KEY, {}).get(TASK_META_NAME_KEY, None)

            if not task_desc_name == meta_task_name:
                continue

            new_config = dict_merge(task_desc, new_config, copy_dct=True)

        task_name = new_config.get(TASKS_META_KEY, {}).get(TASK_NAME_KEY, None)
        if not task_name:
            task_name = meta_task_name

        task_type = new_config.get(TASKS_META_KEY, {}).get(TASK_TYPE_KEY, None)
        roles = new_config.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {})
        task_roles = expand_external_role(roles, self.role_repos)

        int_role_path = get_internal_role_path(task_name, self.role_repos)
        if task_type == EXT_TASK_TYPE:
            if task_name not in roles.keys and task_name not in self.meta_roles.keys() and not int_role_path:
                    raise NsblException("Task name '{}' not found among role names, but task type is '{}'. This is invalid.".format(task_name, task_type))

        else:
            if task_name in task_roles.keys() or task_name in self.meta_roles.keys() or int_role_path:
                task_type = EXT_TASK_TYPE
            else:
                task_type = DYN_TASK_TYPE

            new_config[TASKS_META_KEY][TASK_TYPE_KEY] = task_type

        new_config[TASKS_META_KEY][TASK_NAME_KEY] = task_name
        new_config[TASKS_META_KEY][TASK_ROLES_KEY] = task_roles


        with_items_key = new_config[TASKS_META_KEY].get(WITH_ITEMS_KEY, None)
        if with_items_key:
            new_config[TASKS_META_KEY][TASK_WITH_ITEMS_KEY] = with_items_key

        #TODO: use 'with_items' instead of this
        split_key = new_config[TASKS_META_KEY].get(SPLIT_KEY_KEY, None)
        if split_key:
            splitting = True
        else:
            splitting = False

        if splitting:
            if split_key and isinstance(split_key, string_types):
                split_key = split_key.split("/")

            split_value = new_config
            for split_token in split_key:
                if not isinstance(split_value, dict):
                    raise NsblException("Can't split config value using split key '{}': {}".format(split_key, new_config))
                split_value = split_value.get(split_token, None)
                if not split_value:
                    break

            if split_value and isinstance(split_value, (list, tuple)):

                for item in split_value:
                    item_new_config = copy.deepcopy(new_config)
                    temp = item_new_config
                    for token in split_key[:-1]:
                        temp = temp[token]

                    temp[split_key[-1]] = item

                    yield item_new_config

            else:
                yield new_config
        else:
            yield new_config


class NsblDynamicRoleProcessor(ConfigProcessor):
    """Processor to extract and pre-process single tasks to merge them into one or several roles later on."""

    def validate_init(self):
        self.id_role = 0
        self.current_tasks = []
        self.env_name = self.init_params["env_name"]
        return True

    def handles_last_call(self):

        return True

    def create_role_dict(self, tasks):

        task_vars = {}
        role_name = ["dyn_role"]
        roles = {}

        for idx, t in enumerate(tasks):
            task_id = "_dyn_task_{}".format(idx)
            role_name.append(t[TASKS_META_KEY][TASK_META_NAME_KEY])
            t[TASKS_META_KEY][DYN_TASK_ID_KEY] = task_id
            roles.update(t[TASKS_META_KEY].get(TASK_ROLES_KEY, {}))
            for key, value in t.get(VARS_KEY, {}).items():
                task_vars["{}_{}".format(task_id, key)] = value

        dyn_role = {
            TASKS_META_KEY: {
                TASK_META_NAME_KEY: " ".join(role_name),
                TASK_NAME_KEY: "env_{}_dyn_role_{}".format(self.env_name, self.id_role),
                TASK_DYN_ROLE_DETAILS: copy.deepcopy(self.current_tasks),
                TASK_TYPE_KEY: DYN_ROLE_TYPE,
                TASK_ROLES_KEY: roles
            },
            VARS_KEY: task_vars}

        return dyn_role

    def process_current_config(self):


        if not self.last_call:
            new_config = self.current_input_config

            if new_config[TASKS_META_KEY][TASK_TYPE_KEY] == DYN_TASK_TYPE:
                self.current_tasks.append(new_config)
                yield None
            else:
                if len(self.current_tasks) > 0:
                    dyn_role = self.create_role_dict(self.current_tasks)
                    self.id_role = self.id_role + 1
                    self.current_tasks = []
                    yield dyn_role

                yield new_config
        else:
            if len(self.current_tasks) > 0:
                yield self.create_role_dict(self.current_tasks)
            else:
                yield None


class NsblTasks(object):

    def __init__(self, env, env_id, int_task_descs=[], role_repos=[], env_name="localhost"):

        self.env = env
        self.env_id = env_id
        self.env_name = env_name
        self.role_repos = role_repos
        self.meta_roles = expand_external_role(env.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {}), self.role_repos)
        self.int_task_descs = int_task_descs

        # creating the expanded list of tasks
        nsbl_task_processor = NsblTaskProcessor({'env': self.env, 'task_descs': self.int_task_descs, 'meta_roles': self.meta_roles, 'role_repos': self.role_repos})

        # create the dynamic roles
        nsbl_dynrole_processor = NsblDynamicRoleProcessor({"env_name": self.env_name})

        # id_processor = IdProcessor(NSBL_TASKS_ID_INIT)

        # otherwise each tasks inherits from the ones before
        temp_tasks = [[name] for name in self.env[TASKS_KEY]]

        frkl_format = generate_nsbl_tasks_format(int_task_descs)
        frkl_obj = Frkl(temp_tasks, [
            FrklProcessor(frkl_format),
            nsbl_task_processor, nsbl_dynrole_processor])


        self.tasks = frkl_obj.process()
        for idx, task in enumerate(self.tasks):
            task_id = idx
            task[TASKS_META_KEY][TASK_ID_KEY] = task_id
            task[TASKS_META_KEY][ENV_ID_KEY] = self.env_id

    def get_lookup_dict(self):

        result = {}
        for task in self.tasks:
            id = task[TASKS_META_KEY][TASK_ID_KEY]
            task_type = task[TASKS_META_KEY][TASK_TYPE_KEY]
            if task_type != DYN_ROLE_TYPE:
                if not TASK_DESC_KEY in task[TASKS_META_KEY].keys():
                    temp = {}
                    temp[TASK_NAME_KEY] = task[TASKS_META_KEY][TASK_NAME_KEY]
                    temp[TASK_DESC_KEY] = task[TASKS_META_KEY].get(TASK_DESC_KEY, "applying role: '{}'".format(task[TASKS_META_KEY][TASK_NAME_KEY]))
                    temp[VARS_KEY] = task.get(VARS_KEY, {})
                    result[id] = temp
            else:
                result[id] = {}
                for t in task[TASKS_META_KEY][TASK_DYN_ROLE_DETAILS]:
                    temp = {}
                    temp[TASK_NAME_KEY] = t[TASKS_META_KEY][TASK_NAME_KEY]
                    temp[TASK_DESC_KEY] = t[TASKS_META_KEY].get(TASK_DESC_KEY, t[TASKS_META_KEY][TASK_NAME_KEY])
                    temp[VARS_KEY] = t.get(VARS_KEY, {})
                    result[id][t[TASKS_META_KEY][DYN_TASK_ID_KEY]] = temp

        return result

    def __repr__(self):

        return "NsblTasks(env_id='{}', env_name='{}')".format(self.env_id, self.env_name)

    def get_dict(self):

        temp = {}
        temp["env_name"] = self.env_name
        temp["tasks"] = self.tasks
        # temp["env"] = self.env

        return temp
