# -*- coding: utf-8 -*-

import copy
import json
import shutil
import subprocess

import os
import yaml
from cookiecutter.main import cookiecutter
from frkl import CHILD_MARKER_NAME, DEFAULT_LEAF_NAME, DEFAULT_LEAFKEY_NAME, KEY_MOVE_MAP_NAME, OTHER_KEYS_NAME, \
    UrlAbbrevProcessor, EnsureUrlProcessor, EnsurePythonObjectProcessor, FrklProcessor, \
    IdProcessor
from frkl import Frkl, ConfigProcessor
from jinja2 import Environment, PackageLoader
from six import string_types

try:
    set
except NameError:
    from sets import Set as set

import logging

log = logging.getLogger("nsbl")

# stem key for inventory
ENVS_KEY = "envs"
# meta info for groups/hosts (contains for example 'hosts' for groups)
ENV_META_KEY = "meta"
# name of the group/host
ENV_NAME_KEY = "name"
# type of the environemnt (either group or host)
ENV_TYPE_KEY = "type"
# under meta key, lists hosts of a group
ENV_HOSTS_KEY = "hosts"
# under meta key, lists sub-groups of a group, or which groups a host is member is
ENV_GROUPS_KEY = "groups"
# vars for a host/group
VARS_KEY = "vars"
# tasks for a hosts/group, used to create playbooks
TASKS_KEY = "tasks"

# bootstrap frkl processor chain for creating the inventory hosts/groups lists
NSBL_INVENTORY_BOOTSTRAP_FORMAT = {
    CHILD_MARKER_NAME: ENVS_KEY,
    DEFAULT_LEAF_NAME: ENV_META_KEY,
    DEFAULT_LEAFKEY_NAME: ENV_NAME_KEY,
    OTHER_KEYS_NAME: [VARS_KEY, TASKS_KEY],
    KEY_MOVE_MAP_NAME: VARS_KEY
}
# bootstrap chain used for creating the inventory
NSBL_INVENTORY_BOOTSTRAP_CHAIN = [
    UrlAbbrevProcessor(), EnsureUrlProcessor(), EnsurePythonObjectProcessor(),
    FrklProcessor(NSBL_INVENTORY_BOOTSTRAP_FORMAT)
]

# meta infor for tasks (e.g. 'become')
TASKS_META_KEY = "meta"
# name of the task, can be internal or external role, or an ansible module
TASK_NAME_KEY = "name"
# name that the role has, used in the playbook, added automatically according to the type of task that is processed
ROLE_NAME_KEY = "role"
# the type of task
TASK_TYPE_KEY = "type"
# key to indicate whether a task/role should be executed with superuser privileges
TASK_BECOME_KEY = "become"
# key to tell nsbl which variable keys are valid if the type is ansible module. ansible modules don't like getting fed keys that are not related to them
TASK_ALLOWED_VARS_KEY = "allowed_vars"
# key to indicate which role dependencies should be added for the ansible environment to be created
TASK_ROLES_KEY = "roles"

# indicator for task type internal role
INT_TASK_TYPE = "internal_role"
# indicator for task type external role
EXT_TASK_TYPE = "external_role"
# indicator for task type ansible module
DYN_TASK_TYPE = "single_task"
# indicator for task type autogenerated dynamic role (out of DYN_TASK_TYPEs)
DYN_ROLE_TYPE = "dynamic_role"
# filename that contains meta information for internal roles
ROLE_META_FILENAME = "meta.yml"

DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT = {
    CHILD_MARKER_NAME: TASKS_KEY,
    DEFAULT_LEAF_NAME: TASKS_META_KEY,
    DEFAULT_LEAFKEY_NAME: TASK_NAME_KEY,
    KEY_MOVE_MAP_NAME: {'*': (VARS_KEY, 'free_form')},
    "use_context": True
}
NSBL_TASKS_TEMPLATE_INIT = {
    "use_environment_vars": True,
    "use_context": True
}

ID_NAME = "id"
NSBL_TASKS_ID_INIT = {
    "id_key": TASKS_META_KEY,
    "id_name": ID_NAME
}

ENV_TYPE_HOST = 'host'
ENV_TYPE_GROUP = 'group'
DEFAULT_ENV_TYPE = ENV_TYPE_GROUP

# DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN = [
# UrlAbbrevProcessor(), EnsureUrlProcessor(), Jinja2TemplateProcessor(NSBL_TASKS_TEMPLATE_INIT), EnsurePythonObjectProcessor(), FrklProcessor(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT), IdProcessor(NSBL_TASKS_ID_INIT)
# ]

DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN = [
    FrklProcessor(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT)
]


class NsblException(Exception):
    """Base exception class for nsbl."""

    def __init__(self, message):
        super(NsblException, self).__init__(message)


class RepoRoles(object):
    """Class to encapsulate all folders that contain 'internal' roles.
    """

    def __init__(self, folders):

        if isinstance(folders, string_types):
            self.folders = [folders]
        else:
            self.folders = folders
        self.roles = self.read_role_repos()

    def read_role_repos(self):

        result = {}

        for repo in self.folders:
            for basename in [name for name in os.listdir(repo) if os.path.isdir(os.path.join(repo, name))]:

                roles_metadata = os.path.join(repo, basename, ROLE_META_FILENAME)

                dependencies = []
                default_role = None
                roles = {}
                if os.path.exists(roles_metadata):
                    with open(roles_metadata) as f:
                        content = yaml.load(f)

                    if "dependencies" in content.keys():
                        dependencies = content["dependencies"]
                        if isinstance(dependencies, string_types):
                            dependencies = [dependencies]
                    if "default_role" in content.keys():
                        default_role = content["default_role"]

                    if "roles" in content.keys():
                        roles = content["roles"]

                roles_path = os.path.join(repo, basename, "roles")

                if not default_role and os.path.exists(os.path.join(roles_path, basename)):
                    default_role = basename
                elif not default_role:
                    if os.path.exists(os.path.join(roles_path)):
                        child_dirs = [name for name in os.listdir(roles_path) if
                                      os.path.isdir(os.path.join(roles_path, name))]
                        if len(child_dirs) == 1:
                            default_role = child_dirs[0]
                    else:
                        if len(roles) == 1:
                            default_role = list(roles.keys())[0]
                if not default_role:
                    log.debug("No default role found for '{}', ignoring internal role".format(basename))
                    continue

                if basename in result.keys():
                    raise Exception("Multiple roles/tasks with name in role repositories: {}".format(basename))

                result[basename] = {"roles_path": roles_path, "default_role": default_role,
                                    "dependencies": dependencies, TASK_ROLES_KEY: roles}

        return result


class Nsbl(object):
    def __init__(self, configs, roles_repos, default_env_type=DEFAULT_ENV_TYPE):
        """Wrapper class to create an Ansible environment.

        Args:
          configs (list): the configuration(s) describing the inventory and tasks
          roles_reopos (list): path(s) to all local role repos
          default_env_type (str): the default type for an environment if not provided in the config (either ENV_TYPE_HOST or ENV_TYPE_GROUP)
        """

        self.configs = configs
        if isinstance(roles_repos, string_types):
            roles_repos = [roles_repos]
        elif not isinstance(roles_repos, (list, tuple)):
            raise Exception("roles_repos needs to be string or list: '{}'".format(roles_repos))

        self.roles_repos = roles_repos

        self.repo_roles = RepoRoles(self.roles_repos)
        self.inventory = NsblInventory(self.configs, self.repo_roles, default_env_type)
        self.tasks = []
        self.tasks = self.inventory.tasks

    def get_inventory_config_string(self):

        jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
        template = jinja_env.get_template('hosts')
        output_text = template.render(groups=self.inventory.groups, hosts=self.inventory.hosts)

        return output_text

    def extract_vars(self, inventory_dir):

        for group, group_vars in self.inventory.groups.items():
            vars = group_vars.get(VARS_KEY, {})
            if not vars:
                continue
            group_dir = os.path.join(inventory_dir, "group_vars", group)
            var_file = os.path.join(group_dir, "{}.yml".format(group))
            content = yaml.dump(vars, default_flow_style=False)

            os.makedirs(group_dir)
            with open(var_file, "w") as text_file:
                text_file.write(content)

        for host, host_vars in self.inventory.hosts.items():
            vars = host_vars.get(VARS_KEY, {})
            if not vars:
                continue
            host_dir = os.path.join(inventory_dir, "host_vars", host)
            var_file = os.path.join(host_dir, "{}.yml".format(host))
            content = yaml.dump(vars, default_flow_style=False)

            os.makedirs(host_dir)
            with open(var_file, "w") as text_file:
                text_file.write(content)

    def write_inventory_file_or_script(self, inventory_dir, extract_vars=False, relative_paths=True):

        if extract_vars:
            inventory_string = self.get_inventory_config_string()
            inventory_name = "hosts"
            inventory_file = os.path.join(inventory_dir, inventory_name)

            with open(inventory_file, "w") as text_file:
                text_file.write(inventory_string)

        else:
            # write dynamic inventory script
            jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
            if relative_paths:
                template = jinja_env.get_template('inventory_relative')
            else:
                template = jinja_env.get_template('inventory_absolute')

            roles_repos_string = ""
            if self.roles_repos:
                if relative_paths:
                    roles_repos_string = " --repo ".join(
                        [os.path.relpath(name, inventory_dir) for name in self.roles_repos])

                    rel_configs = []

                    for path in self.configs:
                        rel_path = os.path.relpath(path, inventory_dir)
                        rel_configs.append(rel_path)

                    script_configs = " --config ".join(rel_configs)
                else:
                    roles_repos_string = " --repo ".join([os.path.abspath(name) for name in self.roles_repos])

                    abs_configs = []
                    for path in self.configs:
                        abs_path = os.path.abspath(path)
                        abs_configs.append(abs_path)
                    script_configs = " --config".join(abs_configs)

            output_text = template.render(role_repo_paths=roles_repos_string, nsbl_script_configs=script_configs)

            inventory_string = self.get_inventory_config_string()
            inventory_target_name = "inventory"

            inventory_file = os.path.join(inventory_dir, inventory_target_name)

            with open(inventory_file, "w") as text_file:
                text_file.write(output_text)

            st = os.stat(inventory_file)
            os.chmod(inventory_file, 0o775)

    def render_environment(self, env_dir, extract_vars=False):
        """Creates the ansible environment in the folder provided.

        Args:
          env_dir (str): the folder where the environment should be created
        """

        all_ext_roles = {}
        for tasks in self.tasks:
            all_ext_roles.update(tasks.ext_roles)

        inventory_dir = os.path.join(env_dir, "inventory")

        if extract_vars:
            inv_target = "../inventory/hosts"
        else:
            inv_target = "../inventory/inventory"

        cookiecutter_details = {
            "inventory": inv_target,
            "env_dir": env_dir,
            "nsbl_roles": all_ext_roles,
            "nsbl_callback_plugins": "",
            "nsbl_callback_plugin_name": ""
        }

        log.debug("Creating build environment from template...")
        log.debug("Using cookiecutter details: {}".format(cookiecutter_details))

        template_path = os.path.join(os.path.dirname(__file__), "external", "cookiecutter-ansible-environment")
        cookiecutter(template_path, extra_context=cookiecutter_details, no_input=True)

        if extract_vars:
            self.extract_vars(inventory_dir)

        self.write_inventory_file_or_script(inventory_dir, extract_vars=extract_vars)

        all_int_roles = {}
        all_dyn_roles = {}
        for tasks in self.tasks:
            all_int_roles.update(tasks.int_roles)
            all_dyn_roles.update(tasks.dyn_roles)

        # create dynamic roles
        for role_name, role in all_dyn_roles.items():
            role_local_path = os.path.join(os.path.dirname(__file__), "external", "ansible-role-template")
            # cookiecutter doesn't like input lists, so converting to dict
            tasks = {}
            for task in role:
                task_name = task[TASKS_META_KEY]["task_id"]
                tasks[task_name] = task
                if "allowed_vars" not in task[TASKS_META_KEY].keys():
                    task[TASKS_META_KEY]['allowed_vars'] = list(task[VARS_KEY].keys())
                else:
                    for key in task.get(VARS_KEY, {}).keys():
                        task[TASKS_META_KEY]['allowed_vars'].append(key)

                task[TASKS_META_KEY]['allowed_vars'] = list(set(task[TASKS_META_KEY]['allowed_vars']))

            role_dict = {
                "role_name": role_name,
                "tasks": tasks
            }

            current_dir = os.getcwd()
            int_roles_base_dir = os.path.join(env_dir, "roles", "dynamic")
            os.chdir(int_roles_base_dir)

            cookiecutter(role_local_path, extra_context=role_dict, no_input=True)
            os.chdir(current_dir)

        # create internal roles
        for role_name, role in all_int_roles.items():
            target = os.path.join(env_dir, "roles", "internal", role_name)
            shutil.copytree(role, target)

        if all_ext_roles:
            # download external roles
            log.debug("Downloading and installing external roles...")
            res = subprocess.check_output([os.path.join(env_dir, "extensions", "setup", "role_update.sh")])
            for line in res.splitlines():
                log.debug("Installing role: {}".format(line.encode('utf8')))

        playbooks = []
        for idx, task in enumerate(self.tasks):
            jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
            template = jinja_env.get_template('playbook.yml')
            output_text = template.render(groups=task.env_name, tasks=task.tasks, env=task.env)

            playbook_name = "play_{}_{}.yml".format(idx, task.env_name)
            playbooks.append(playbook_name)
            playbook_file = os.path.join(env_dir, "plays", playbook_name)

            with open(playbook_file, "w") as text_file:
                text_file.write(output_text)

        template = jinja_env.get_template('play.yml')
        output_text = template.render(playbooks=playbooks)
        all_plays_name = "play.yml"
        all_plays_file = os.path.join(env_dir, "plays", all_plays_name)

        with open(all_plays_file, "w") as text_file:
            text_file.write(output_text)


class NsblInventory(object):
    def __init__(self, configs, repo_roles={}, default_env_type=DEFAULT_ENV_TYPE):
        """Class to be used to create a dynamic ansible inventory from (elastic) yaml config files.

        Args:
          configs (list): list of paths to inventory config (elastic) yaml files
          repo_roles (list): path(s) to all local role repos
          default_env_type (str): the default type for an environment if not provided in the config (either ENV_TYPE_HOST or ENV_TYPE_GROUP)
        """

        self.frkl_obj = Frkl(configs, NSBL_INVENTORY_BOOTSTRAP_CHAIN)
        self.config = self.frkl_obj.process()
        self.default_env_type = default_env_type
        self.repo_roles = repo_roles
        self.groups = {}
        self.hosts = {}
        self.tasks = []

        self.assemble_groups()

    def add_group(self, group_name, group_vars):
        """Add a group to the dynamic inventory.

        Args:
          group_name (str): the name of the group
          group_vars (dict): the variables for this group
        """

        if group_name in self.groups.keys():
            raise NsblException("Group '{}' defined twice".format(group_name))

        self.groups[group_name] = {}
        self.groups[group_name]["vars"] = group_vars
        self.groups[group_name]["hosts"] = []
        self.groups[group_name]["children"] = []

    def add_host(self, host_name, host_vars):
        """Add a host to the dynamic inventory.

        Args:
          host_name (str): the name of the host
          host_vars (dict): the variables for this host
        """

        if host_name not in self.hosts.keys():
            self.hosts[host_name] = {VARS_KEY: {}}

        if not host_vars:
            return

        intersection = set(self.hosts[host_name].keys()).intersection(host_vars.keys())
        if intersection:
            raise NsblException(
                "Adding host more than once with intersecting keys, this is not possible because it's not clear which vars should take precedence. Intersection: {}".format(
                    intersection))

        self.hosts[host_name].update(host_vars)

    def add_group_to_group(self, child, group):
        """Adds a group as a subgroup of another group.

        Args:
          child (str): the name of the sub-group
          group (str): the name of the parent group
        """

        if group not in self.groups[group]["children"]:
            self.groups[group]["children"].append(child)

    def add_host_to_group(self, host, group):
        """Adds a host to a group.

        Args:
          host (str): the name of the host
          group (str): the name of the parent group
        """

        if host not in self.groups[group]["hosts"]:
            self.groups[group]["hosts"].append(host)

        self.add_host(host, None)

    def assemble_groups(self):
        """Kicks of the processing of the config files."""

        for env in self.config:
            if ENV_META_KEY not in env.keys():
                raise NsblException(
                    "Environment does not have metadata (missing '{}') key: {})".format(ENV_META_KEY, env))
            env_type = env[ENV_META_KEY].get(ENV_TYPE_KEY, False)
            if not env_type:
                if ENV_HOSTS_KEY in env[ENV_META_KEY].keys():
                    env_type = ENV_TYPE_GROUP
                elif ENV_GROUPS_KEY in env[ENV_META_KEY].keys():
                    env_type = ENV_TYPE_HOST
                else:
                    env_type = self.default_env_type

            env_name = env[ENV_META_KEY].get(ENV_NAME_KEY, False)
            if not env_name:
                raise NsblException(
                    "Environment metadata needs to contain a name (either host- or group-name): {}".format(
                        env[ENV_META_KEY]))

            if env_type == ENV_TYPE_HOST:
                self.add_host(env_name, env[VARS_KEY])

                if ENV_HOSTS_KEY in env[ENV_META_KEY].keys():
                    raise NsblException(
                        "An environment of type {} can't contain the {} key".format(ENV_TYPE_HOST, ENV_HOSTS_KEY))

                for group in env[ENV_META_KEY].get(ENV_GROUPS_KEY, []):
                    self.add_host_to_group(env_name, group)

            elif env_type == ENV_TYPE_GROUP:

                self.add_group(env_name, env.get(VARS_KEY, {}))

                for host in env[ENV_META_KEY].get(ENV_HOSTS_KEY, []):
                    self.add_host_to_group(host, env_name)

                for group in env[ENV_META_KEY].get(ENV_GROUPS_KEY, []):
                    self.add_group_to_group(group, env_name)

            else:
                raise NsblException("Environment type needs to be either 'host' or 'group': {}".format(env_type))

            if TASKS_KEY in env.keys():
                self.tasks.append(NsblTaskList(env, self.repo_roles, env_name))

        if "localhost" in self.hosts.keys() and "ansible_connection" not in self.hosts["localhost"].get(VARS_KEY,
                                                                                                        {}).keys():
            self.hosts["localhost"][VARS_KEY]["ansible_connection"] = "local"

    def list(self):
        """Lists all groups in the format that is required for ansible dynamic inventories.

        More info: https://docs.ansible.com/ansible/intro_dynamic_inventory.html, http://docs.ansible.com/ansible/dev_guide/developing_inventory.html

        Returns:
        dict: a dict containing all information about all hosts/groups
        """

        result = copy.copy(self.groups)
        result["_meta"] = {"hostvars": self.hosts}

        return json.dumps(result, sort_keys=4, indent=4)

    def host(self, host):
        """Returns the inventory information for the specified host, in the format required for ansible dynamic inventories.

        Args:
          host (str): the name of the host
        Returns:
        dict: all inventory information for this host
        """

        host_vars = self.hosts.get(host, {})
        return json.dumps(host_vars, sort_keys=4, indent=4)

    def get_vars(self, env_name):
        """Returns all variables for the environment with the specified name.

        First tries whether the name matches a group, then tries hosts.

        Args:
          env_name (str): the name of the group or host
        Returns:
          dict: the variables for the environment
        """

        if env_name in self.groups.keys():
            return self.groups[env_name]
        elif env_name in self.hosts.keys():
            return self.hosts[env_name]
        else:
            raise NsblException("Neither group or host with name '{}' exists".format(env_name))


class NsblTaskProcessor(ConfigProcessor):
    """Processor to take a list of (unfrklized) tasks, and frklizes (expands) the data.

    In particular, this extracts roles and tags them with their types.
    """

    def validate_init(self):

        self.meta_roles = self.init_params['env'].get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {})
        self.repo_roles = self.init_params['repo_roles']

        return True

    def process_current_config(self):

        new_config = self.current_input_config

        roles = new_config.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {})

        task_name = new_config[TASKS_META_KEY][TASK_NAME_KEY]

        if task_name in self.repo_roles.roles.keys():
            task_type = INT_TASK_TYPE
            task_roles = self.repo_roles.roles[task_name]

        elif task_name in roles.keys() or task_name in self.meta_roles.keys():
            task_type = EXT_TASK_TYPE
            task_roles = self.expand_external_role(roles)
        else:
            task_type = DYN_TASK_TYPE
            task_roles = {}

        new_config[TASKS_META_KEY][TASK_TYPE_KEY] = task_type
        new_config[TASKS_META_KEY][TASK_ROLES_KEY] = task_roles
        return new_config

    def expand_external_role(self, role_dict):

        result = {}
        for role_name, role_details in role_dict.items():
            temp_role = {}
            if isinstance(role_details, string_types):
                temp_role["url"] = role_details
            elif isinstance(role_details, dict):
                temp_role["url"] = role_details["url"]
                if "version" in role_details.keys():
                    temp_role["version"] = role_details["version"]
            result[role_name] = temp_role

        return result


class NsblDynamicRoleProcessor(ConfigProcessor):
    """Processor to extract and pre-process single tasks to merge them into one or several roles later on."""

    def validate_init(self):
        self.id_role = 0
        self.current_tasks = []
        self.env_name = self.init_params["env_name"]
        return True

    def handles_last_call(self):

        return True

    def create_role_dict(self, tasks):

        task_vars = {}
        for idx, t in enumerate(tasks):
            task_id = "_dyn_role_task_{}".format(idx)
            t[TASKS_META_KEY]["task_id"] = task_id
            for key, value in t.get(VARS_KEY, {}).items():
                task_vars["{}_{}".format(task_id, key)] = value

        dyn_role = {
            TASKS_META_KEY: {
                TASK_NAME_KEY: "env_{}_dyn_role_{}".format(self.env_name, self.id_role),
                TASK_ROLES_KEY: copy.deepcopy(self.current_tasks),
                TASK_TYPE_KEY: DYN_ROLE_TYPE
            },
            VARS_KEY: task_vars}

        return dyn_role

    def process_current_config(self):

        if not self.last_call:

            new_config = self.current_input_config

            if new_config[TASKS_META_KEY][TASK_TYPE_KEY] == DYN_TASK_TYPE:
                self.current_tasks.append(new_config)
                yield None
            else:
                if len(self.current_tasks) > 0:
                    dyn_role = self.create_role_dict(self.current_tasks)
                    self.id_role = self.id_role + 1
                    self.current_tasks = []
                    yield dyn_role

                yield new_config
        else:
            if len(self.current_tasks) > 0:
                yield self.create_role_dict(self.current_tasks)
            else:
                yield None


class NsblTaskList(object):
    def __init__(self, env, repo_roles, env_name="localhost"):
        """Holds a list of tasks, extracts and sorts roles (internal, external, dynamic)."""

        self.env = env
        self.env_name = env_name
        self.repo_roles = repo_roles

        nsbl_task_processor = NsblTaskProcessor({'env': self.env, 'repo_roles': self.repo_roles})

        nsbl_dynrole_processor = NsblDynamicRoleProcessor({"env_name": self.env_name})
        id_processor = IdProcessor(NSBL_TASKS_ID_INIT)

        # otherwise each tasks inherits from the ones before
        temp_tasks = [[name] for name in self.env[TASKS_KEY]]
        frkl_obj = Frkl(temp_tasks, DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN + [nsbl_task_processor, nsbl_dynrole_processor,
                                                                          id_processor])

        self.tasks = frkl_obj.process()
        self.ext_roles = {}
        self.int_roles = {}
        self.dyn_roles = {}

        self.process_tasks()

        # for task, roles in self.dyn_roles.items():
        # print("-------------------")
        # pprint.pprint(task)
        # pprint.pprint(roles)
        # print("---")

    def add_ext_roles(self, new_roles):

        for role_name, role in new_roles.items():
            if role_name in self.ext_roles.keys():
                if role != self.ext_roles["role_name"]:
                    raise Exception(
                        "Role '{}' added multiple times, with different urls/versions: {} - {}".format(role_name, role,
                                                                                                       self.ext_roles[
                                                                                                           role_name]))
            else:
                self.ext_roles[role_name] = role

    def add_int_role(self, role):

        roles_path = role["roles_path"]
        child_dirs = [name for name in os.listdir(roles_path) if os.path.isdir(os.path.join(roles_path, name))]
        for role_dir_name in child_dirs:
            if role_dir_name in self.int_roles.keys():
                log.debug("Internal role with name '{}' added multiple times, ignoring this: {}".format(role_dir_name,
                                                                                                        os.path.join(
                                                                                                            roles_path,
                                                                                                            role_dir_name)))
            else:
                self.int_roles[role_dir_name] = os.path.join(roles_path, role_dir_name)

        dependencies = role.get("dependencies", [])
        for dep in dependencies:
            if not dep in self.int_roles.keys():
                self.add_int_role(self.repo_roles.roles[dep])
            else:
                log.debug("(Internal role) dependency '{}' already added, ignoring.".format(dep))

    def add_dyn_role(self, role_name, tasks):

        for t in tasks:
            if VARS_KEY not in t.keys():
                t[VARS_KEY] = {}
        self.dyn_roles[role_name] = tasks

    def get_dict(self):

        temp = {}
        temp["env_name"] = self.env_name
        temp["tasks"] = self.tasks
        # temp["env"] = self.env

        return temp

    def process_tasks(self):

        for task in self.tasks:

            task_type = task[TASKS_META_KEY][TASK_TYPE_KEY]
            if task_type == INT_TASK_TYPE:
                # new_ext_roles = task[TASKS_META_KEY][TASK_ROLES_KEY][TASK_ROLES_KEY]
                # self.add_ext_roles(new_ext_roles)
                self.add_int_role(task[TASKS_META_KEY][TASK_ROLES_KEY])
                task[TASKS_META_KEY][ROLE_NAME_KEY] = task[TASKS_META_KEY][TASK_ROLES_KEY]['default_role']
            elif task_type == DYN_ROLE_TYPE:
                name = task[TASKS_META_KEY][TASK_NAME_KEY]
                self.add_dyn_role(name, task[TASKS_META_KEY][TASK_ROLES_KEY])
                task[TASKS_META_KEY][ROLE_NAME_KEY] = task[TASKS_META_KEY][TASK_NAME_KEY]
            elif task_type == EXT_TASK_TYPE:
                new_roles = task[TASKS_META_KEY][TASK_ROLES_KEY]
                self.add_ext_roles(new_roles)
                task[TASKS_META_KEY][ROLE_NAME_KEY] = task[TASKS_META_KEY][TASK_NAME_KEY]

            else:
                raise Exception("Task type '{}' not known.".format(task_type))
