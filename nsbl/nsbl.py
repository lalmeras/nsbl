# -*- coding: utf-8 -*-

import copy
import pprint
import json
import shutil
import subprocess
import sys

import os
import yaml
from cookiecutter.main import cookiecutter
from frkl import CHILD_MARKER_NAME, DEFAULT_LEAF_NAME, DEFAULT_LEAFKEY_NAME, KEY_MOVE_MAP_NAME, OTHER_KEYS_NAME, \
    UrlAbbrevProcessor, EnsureUrlProcessor, EnsurePythonObjectProcessor, FrklProcessor, \
    IdProcessor, dict_merge
from frkl import Frkl, ConfigProcessor
from jinja2 import Environment, PackageLoader
from six import string_types

try:
    set
except NameError:
    from sets import Set as set

import logging

log = logging.getLogger("nsbl")

# stem key for inventory
ENVS_KEY = "envs"
# meta info for groups/hosts (contains for example 'hosts' for groups)
ENV_META_KEY = "meta"
# name of the group/host
ENV_NAME_KEY = "name"
# type of the environemnt (either group or host)
ENV_TYPE_KEY = "type"
# under meta key, lists hosts of a group
ENV_HOSTS_KEY = "hosts"
# under meta key, lists sub-groups of a group, or which groups a host is member is
ENV_GROUPS_KEY = "groups"
# vars for a host/group
VARS_KEY = "vars"
# tasks for a hosts/group, used to create playbooks
TASKS_KEY = "tasks"

# bootstrap frkl processor chain for creating the inventory hosts/groups lists
NSBL_INVENTORY_BOOTSTRAP_FORMAT = {
    CHILD_MARKER_NAME: ENVS_KEY,
    DEFAULT_LEAF_NAME: ENV_META_KEY,
    DEFAULT_LEAFKEY_NAME: ENV_NAME_KEY,
    OTHER_KEYS_NAME: [VARS_KEY, TASKS_KEY],
    KEY_MOVE_MAP_NAME: VARS_KEY
}
# bootstrap chain used for creating the inventory
NSBL_INVENTORY_BOOTSTRAP_CHAIN = [
    UrlAbbrevProcessor(), EnsureUrlProcessor(), EnsurePythonObjectProcessor(),
    FrklProcessor(NSBL_INVENTORY_BOOTSTRAP_FORMAT)]

TASK_DESC_DEFAULT_FILENAME = "task-descs.yml"

# meta infor for tasks (e.g. 'become')
TASKS_META_KEY = "meta"
# name of the task, can be internal or external role, or an ansible module
TASK_META_NAME_KEY = "name"
# name that the role has, used in the playbook, added automatically according to the type of task that is processed
ROLE_NAME_KEY = "role"
# the type of task
TASK_TYPE_KEY = "task-type"
# key to indicate whether a task/role should be executed with superuser privileges
TASK_BECOME_KEY = "become"
# key to tell nsbl which variable keys are valid if the type is ansible module. ansible modules don't like getting fed keys that are not related to them
TASK_ALLOWED_VARS_KEY = "allowed_vars"
# key to indicate which role dependencies should be added for the ansible environment to be created
TASK_ROLES_KEY = "task-roles"
TASK_DYN_ROLE_DETAILS = "task-dyn-role-details"
# key to indicate allowed keys for an ansible module
VAR_KEYS_KEY = "var_keys"
# name that gets used by ansible, either a module name, or a role name
TASK_NAME_KEY = "task-name"

DEFAULT_KEY_KEY = "default-key"
SPLIT_KEY_KEY = "split-key"

# indicator for task type internal role
INT_TASK_TYPE = "internal_role"
# indicator for task type external role
EXT_TASK_TYPE = "external_role"
# indicator for task type ansible module
DYN_TASK_TYPE = "single_task"
# indicator for task type autogenerated dynamic role (out of DYN_TASK_TYPEs)
DYN_ROLE_TYPE = "dynamic_role"
# filename that contains meta information for internal roles
ROLE_META_FILENAME = "meta.yml"

DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT = {
    CHILD_MARKER_NAME: TASKS_KEY,
    DEFAULT_LEAF_NAME: TASKS_META_KEY,
    DEFAULT_LEAFKEY_NAME: TASK_META_NAME_KEY,
    KEY_MOVE_MAP_NAME: {'*': (VARS_KEY, 'default')},
    "use_context": True
}

def generate_nsbl_tasks_format(task_descs):

    result = copy.deepcopy(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT)

    for task_desc in task_descs:
        if DEFAULT_KEY_KEY in task_desc[TASKS_META_KEY].keys():
            result[KEY_MOVE_MAP_NAME][task_desc[TASKS_META_KEY][TASK_META_NAME_KEY]] = task_desc[TASKS_META_KEY][DEFAULT_KEY_KEY]

    return result

NSBL_TASKS_TEMPLATE_INIT = {
    "use_environment_vars": True,
    "use_context": True
}

ID_NAME = "id"
NSBL_TASKS_ID_INIT = {
    "id_key": TASKS_META_KEY,
    "id_name": ID_NAME
}

ENV_TYPE_HOST = 'host'
ENV_TYPE_GROUP = 'group'
DEFAULT_ENV_TYPE = ENV_TYPE_GROUP

# DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN = [
# UrlAbbrevProcessor(), EnsureUrlProcessor(), Jinja2TemplateProcessor(NSBL_TASKS_TEMPLATE_INIT), EnsurePythonObjectProcessor(), FrklProcessor(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT), IdProcessor(NSBL_TASKS_ID_INIT)
# ]

DEFAULT_NSBL_TASKS_BOOTSTRAP_CHAIN = [
    FrklProcessor(DEFAULT_NSBL_TASKS_BOOTSTRAP_FORMAT)
]

# ------------------------------
# util functions
def get_pkg_mgr_sudo(mgr):
    """Simple function to determine whether a given package manager needs sudo rights or not.
    """
    if mgr == 'no_install':
        return False
    elif mgr == 'nix':
        return False
    elif mgr == 'conda':
        return False
    elif mgr == 'git':
        return False
    elif mgr == 'homebrew':
        return False
    else:
        return True

def get_local_role_desc(role_name, role_repos=[]):

    url = False
    if os.path.exists(role_name):
        url = role_name
    else:
        for repo in role_repos:
            path = os.path.join(os.path.expanduser(repo), role_name)
            if os.path.exists(path):
                url = role_name

    if not url:
        raise NsblException("Can't find local role '{}' (neither as absolute path nor in any of the local role repos)".format(role_name))

    return {"url": url}

def merge_roles(role_obj, role_repos=[]):

    role_dict = {}

    if isinstance(role_obj, dict):
        if "url" in role_obj.keys() or "version" in role_obj.keys():
            raise NsblException("Although dictionaries and lists can be mixed for the {} key, dictionaries need to use role-names as keys, the keyworkds 'url' and 'version' are not allowed. Mostly likely this is a misconfiguration.")
        role_dict.update(role_obj)
    elif isinstance(role_obj, string_types):
        temp = get_local_role_desc(role_obj, role_repos)
        role_dict[role_obj] = temp
    elif isinstance(role_obj, (list, tuple)):
        for role_obj_child in role_obj:
            temp = merge_roles(role_obj_child, role_repos)
            role_dict.update(temp)
    else:
        raise NsblException("Role description needs to be either a list of strings or a dict. Value '{}' is not valid.".format(role_obj))

    return role_dict

def expand_external_role(role_dict, role_repos=[]):

    temp_role_dict = merge_roles(role_dict, role_repos)

    result = {}
    for role_name, role_details in temp_role_dict.items():
        temp_role = {}
        if isinstance(role_details, string_types):
            temp_role["url"] = role_details
        elif isinstance(role_details, dict):
            temp_role["url"] = role_details["url"]
            if "version" in role_details.keys():
                temp_role["version"] = role_details["version"]
        result[role_name] = temp_role

    return result

def get_internal_role_path(role_dict, role_repos=[]):

    if isinstance(role_dict, string_types):
        url = role_dict
    elif isinstance(role_dict, dict):
        url = role_dict["url"]
    else:
        raise NsblException("Type '{}' not supported for role description: {}".format(type(role_dict), role_dict))

    if os.path.exists(url):
        return url

    for repo in role_repos:
        path = os.path.join(os.path.expanduser(repo), url)
        if os.path.exists(path):
            return path

    return False




class NsblException(Exception):
    """Base exception class for nsbl."""

    def __init__(self, message):
        super(NsblException, self).__init__(message)


class Nsbl(object):
    def __init__(self, configs, int_task_descs=None, role_repos=None, default_env_type=DEFAULT_ENV_TYPE, use_default_roles=True, use_repo_task_descs=True):
        """Wrapper class to create an Ansible environment.

        Args:
          configs (list): the configuration(s) describing the inventory and tasks
          int_tasks_descs (list): path(s)/urls to all local role repos
          default_env_type (str): the default type for an environment if not provided in the config (either ENV_TYPE_HOST or ENV_TYPE_GROUP)
          use_default_roles (bool): whether to use the default roles that come with nsbl
          use_repo_task_descs (bool): whether to use task descriptions that come with roles repos (filename: TASK_DESC_DEFAULT_FILENAME in repo root directory)
        """

        self.configs = configs

        if not role_repos:
            role_repos = []

        if isinstance(role_repos, string_types):
            self.role_repos = [role_repos]
        else:
            self.role_repos = role_repos

        default_roles_path = os.path.join(os.path.dirname(__file__), "external", "default-roles")

        if not self.role_repos:
            self.role_repos.append(default_roles_path)
        elif use_default_roles:
            self.role_repos.insert(0, default_roles_path)

        #TODO: check whether paths exist

        if isinstance(int_task_descs, string_types):
            int_task_descs = [int_task_descs]
        elif not isinstance(int_task_descs, (list, tuple)):
            raise Exception("task_descs needs to be string or list: '{}'".format(int_task_descs))

        if not int_task_descs:
            int_task_descs = []

        if use_repo_task_descs:
            repo_int_task_descs = []
            for repo in self.role_repos:
                task_desc_file = os.path.join(os.path.expanduser(repo), TASK_DESC_DEFAULT_FILENAME)
                if os.path.exists(task_desc_file):
                    repo_int_task_descs.append(task_desc_file)

            int_task_descs = repo_int_task_descs + int_task_descs

        #TODO: check whether paths exist

        frkl_format = generate_nsbl_tasks_format([])
        task_desk_frkl = Frkl(int_task_descs, [UrlAbbrevProcessor(),
                                               EnsureUrlProcessor(),
                                               EnsurePythonObjectProcessor(),
                                               FrklProcessor(frkl_format)])

        self.int_task_descs = task_desk_frkl.process()

        self.inventory = NsblInventory(self.configs, self.int_task_descs, self.role_repos, default_env_type)
        self.tasks = self.inventory.tasks

    def render_environment(self, env_dir, extract_vars=False, force=False):
        """Creates the ansible environment in the folder provided.

        Args:
          env_dir (str): the folder where the environment should be created
          extract_vars (bool): whether to extract a hostvars and groupvars directory for the inventory (True), or render a dynamic inventory script for the environment (default, False)
        """

        if os.path.exists(env_dir) and force:
            shutil.rmtree(env_dir)

        all_ext_roles = {}
        all_int_roles = {}
        #TODO: check for duplicate and different roles
        for tasks in self.tasks:
            meta_roles = tasks.meta_roles
            for role_name, role_dict in meta_roles.items():
                role_path = get_internal_role_path(role_dict, self.role_repos)
                if role_path:
                    all_int_roles[role_name] = role_path
                else:
                    all_ext_roles[role_name] = role_dict
            for t in tasks.tasks:
                task_name = t[TASKS_META_KEY][TASK_NAME_KEY]
                local_role = get_internal_role_path(task_name, self.role_repos)
                if local_role:
                    all_int_roles[task_name] = local_role
                roles = t.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {})
                for role_name, role_dict in roles.items():
                    role_path = get_internal_role_path(role_dict, self.role_repos)
                    if role_path:
                        all_int_roles[role_name] = role_path
                    else:
                        all_ext_roles[role_name] = role_dict

        inventory_dir = os.path.join(env_dir, "inventory")

        if extract_vars:
            inv_target = "../inventory/hosts"
        else:
            inv_target = "../inventory/inventory"

        playbook_dir = os.path.join(env_dir, "plays")
        ask_sudo = ""
        all_plays_name = "all_plays.yml"

        library_path = os.path.join(os.path.dirname(__file__), "external", "extra_plugins", "library")
        action_plugins_path = os.path.join(os.path.dirname(__file__), "external", "extra_plugins", "action_plugins")

        cookiecutter_details = {
            "inventory": inv_target,
            "env_dir": env_dir,
            "playbook_dir": playbook_dir,
            "library_path": library_path,
            "action_plugins_path": action_plugins_path,
            "extra_script_commands": "",
            "ask_sudo": ask_sudo,
            "playbook": all_plays_name,
            "nsbl_roles": all_ext_roles,
            "nsbl_callback_plugins": "",
            "nsbl_callback_plugin_name": ""
        }

        log.debug("Creating build environment from template...")
        log.debug("Using cookiecutter details: {}".format(cookiecutter_details))

        template_path = os.path.join(os.path.dirname(__file__), "external", "cookiecutter-ansible-environment")

        cookiecutter(template_path, extra_context=cookiecutter_details, no_input=True)

        if extract_vars:
            self.inventory.extract_vars(inventory_dir)

        self.inventory.write_inventory_file_or_script(inventory_dir, extract_vars=extract_vars)


        # copy internal roles
        for role_name, role in all_int_roles.items():
            target = os.path.join(env_dir, "roles", "internal", role_name)
            shutil.copytree(role, target)

        all_dyn_roles = {}
        for tasks in self.tasks:
            for task in tasks.tasks:
                if task[TASKS_META_KEY][TASK_TYPE_KEY] == DYN_ROLE_TYPE:
                    all_dyn_roles[task[TASKS_META_KEY][TASK_NAME_KEY]] = task[TASKS_META_KEY][TASK_DYN_ROLE_DETAILS]

        # create dynamic roles
        for role_name, role_tasks in all_dyn_roles.items():
            role_local_path = os.path.join(os.path.dirname(__file__), "external", "ansible-role-template")
            # cookiecutter doesn't like input lists, so converting to dict
            tasks = {}

            for task in role_tasks:
                task_name = task[TASKS_META_KEY]["task_id"]
                tasks[task_name] = task
                if VARS_KEY not in task.keys():
                    task[VARS_KEY] = {}
                if VAR_KEYS_KEY not in task[TASKS_META_KEY].keys():
                    task[TASKS_META_KEY][VAR_KEYS_KEY] = list(task.get(VARS_KEY, {}).keys())
                else:
                    for key in task.get(VARS_KEY, {}).keys():
                        task[TASKS_META_KEY][VAR_KEYS_KEY].append(key)

                task[TASKS_META_KEY][VAR_KEYS_KEY] = list(set(task[TASKS_META_KEY][VAR_KEYS_KEY]))

            role_dict = {
                "role_name": role_name,
                "tasks": tasks,
                "dependencies": ""
            }

            current_dir = os.getcwd()
            int_roles_base_dir = os.path.join(env_dir, "roles", "dynamic")
            os.chdir(int_roles_base_dir)

            cookiecutter(role_local_path, extra_context=role_dict, no_input=True)
            os.chdir(current_dir)

        if all_ext_roles:
            # download external roles
            log.debug("Downloading and installing external roles...")
            res = subprocess.check_output([os.path.join(env_dir, "extensions", "setup", "role_update.sh")])
            for line in res.splitlines():
                log.debug("Installing role: {}".format(line.encode('utf8')))

        playbooks = []
        for idx, task in enumerate(self.tasks):
            jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
            template = jinja_env.get_template('playbook.yml')
            output_text = template.render(groups=task.env_name, tasks=task.tasks, env=task.env)

            playbook_name = "play_{}_{}.yml".format(idx, task.env_name)
            playbooks.append(playbook_name)
            playbook_file = os.path.join(env_dir, "plays", playbook_name)

            with open(playbook_file, "w") as text_file:
                text_file.write(output_text)

        template = jinja_env.get_template('play.yml')
        output_text = template.render(playbooks=playbooks)
        all_plays_file = os.path.join(env_dir, "plays", all_plays_name)

        with open(all_plays_file, "w") as text_file:
            text_file.write(output_text)


class NsblInventory(object):

    def __init__(self, configs, int_task_descs=[], role_repos=[], default_env_type=DEFAULT_ENV_TYPE):
        """Class to be used to create a dynamic ansible inventory from (elastic) yaml config files.

        Args:
          configs (list): list of paths to inventory config (elastic) yaml files
          int_task_descs (list): descriptions of internal tasks (used to 'expand' task name keywords)
          default_env_type (str): the default type for an environment if not provided in the config (either ENV_TYPE_HOST or ENV_TYPE_GROUP)
        """

        self.configs = configs
        self.frkl_obj = Frkl(configs, NSBL_INVENTORY_BOOTSTRAP_CHAIN)
        self.config = self.frkl_obj.process()
        self.default_env_type = default_env_type
        self.int_task_deskcs = int_task_descs
        self.role_repos = role_repos
        self.groups = {}
        self.hosts = {}
        self.tasks = []

        self.assemble_groups()

    def extract_vars(self, inventory_dir):

        for group, group_vars in self.groups.items():
            vars = group_vars.get(VARS_KEY, {})
            if not vars:
                continue
            group_dir = os.path.join(inventory_dir, "group_vars", group)
            var_file = os.path.join(group_dir, "{}.yml".format(group))
            content = yaml.dump(vars, default_flow_style=False)

            os.makedirs(group_dir)
            with open(var_file, "w") as text_file:
                text_file.write(content)

        for host, host_vars in self.hosts.items():
            vars = host_vars.get(VARS_KEY, {})
            if not vars:
                continue
            host_dir = os.path.join(inventory_dir, "host_vars", host)
            var_file = os.path.join(host_dir, "{}.yml".format(host))
            content = yaml.dump(vars, default_flow_style=False)

            os.makedirs(host_dir)
            with open(var_file, "w") as text_file:
                text_file.write(content)

    def get_inventory_config_string(self):

        jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
        template = jinja_env.get_template('hosts')
        output_text = template.render(groups=self.groups, hosts=self.hosts)

        return output_text

    def write_inventory_file_or_script(self, inventory_dir, extract_vars=False, relative_paths=True):

        if extract_vars:
            inventory_string = self.get_inventory_config_string()
            inventory_name = "hosts"
            inventory_file = os.path.join(inventory_dir, inventory_name)

            with open(inventory_file, "w") as text_file:
                text_file.write(inventory_string)

        else:
            # write dynamic inventory script
            jinja_env = Environment(loader=PackageLoader('nsbl', 'templates'))
            if relative_paths:
                template = jinja_env.get_template('inventory_relative')
            else:
                template = jinja_env.get_template('inventory_absolute')

            roles_repos_string = ""
            if self.roles_repo_folders:
                if relative_paths:
                    roles_repos_string = " --repo ".join(
                        [os.path.relpath(name, inventory_dir) for name in self.roles_repo_folders])

                    rel_configs = []

                    for path in self.configs:
                        rel_path = os.path.relpath(path, inventory_dir)
                        rel_configs.append(rel_path)

                    script_configs = " --config ".join(rel_configs)
                else:
                    roles_repos_string = " --repo ".join([os.path.abspath(name) for name in self.roles_repos])

                    abs_configs = []
                    for path in self.configs:
                        abs_path = os.path.abspath(path)
                        abs_configs.append(abs_path)
                    script_configs = " --config".join(abs_configs)

            output_text = template.render(role_repo_paths=roles_repos_string, nsbl_script_configs=script_configs)

            inventory_string = self.get_inventory_config_string()
            inventory_target_name = "inventory"

            inventory_file = os.path.join(inventory_dir, inventory_target_name)

            with open(inventory_file, "w") as text_file:
                text_file.write(output_text)

            st = os.stat(inventory_file)
            os.chmod(inventory_file, 0o775)

    def add_group(self, group_name, group_vars):
        """Add a group to the dynamic inventory.

        Args:
          group_name (str): the name of the group
          group_vars (dict): the variables for this group
        """

        if group_name in self.groups.keys():
            raise NsblException("Group '{}' defined twice".format(group_name))

        self.groups[group_name] = {}
        self.groups[group_name]["vars"] = group_vars
        self.groups[group_name]["hosts"] = []
        self.groups[group_name]["children"] = []

    def add_host(self, host_name, host_vars):
        """Add a host to the dynamic inventory.

        Args:
          host_name (str): the name of the host
          host_vars (dict): the variables for this host
        """

        if host_name not in self.hosts.keys():
            self.hosts[host_name] = {VARS_KEY: {}}

        if not host_vars:
            return

        intersection = set(self.hosts[host_name].get(VARS_KEY, {}).keys()).intersection(host_vars.keys())

        if intersection:
            raise NsblException(
                "Adding host more than once with intersecting keys, this is not possible because it's not clear which vars should take precedence. Intersection: {}".format(
                    intersection))

        self.hosts[host_name][VARS_KEY].update(host_vars)

    def add_group_to_group(self, child, group):
        """Adds a group as a subgroup of another group.

        Args:
          child (str): the name of the sub-group
          group (str): the name of the parent group
        """

        if group not in self.groups[group]["children"]:
            self.groups[group]["children"].append(child)

    def add_host_to_group(self, host, group):
        """Adds a host to a group.

        Args:
          host (str): the name of the host
          group (str): the name of the parent group
        """

        if host not in self.groups[group]["hosts"]:
            self.groups[group]["hosts"].append(host)

        self.add_host(host, None)

    def assemble_groups(self):
        """Kicks of the processing of the config files."""

        for env in self.config:
            if ENV_META_KEY not in env.keys():
                raise NsblException(
                    "Environment does not have metadata (missing '{}') key: {})".format(ENV_META_KEY, env))
            env_type = env[ENV_META_KEY].get(ENV_TYPE_KEY, False)
            if not env_type:
                if ENV_HOSTS_KEY in env[ENV_META_KEY].keys():
                    env_type = ENV_TYPE_GROUP
                elif ENV_GROUPS_KEY in env[ENV_META_KEY].keys():
                    env_type = ENV_TYPE_HOST
                else:
                    env_type = self.default_env_type

            env_name = env[ENV_META_KEY].get(ENV_NAME_KEY, False)
            if not env_name:
                raise NsblException(
                    "Environment metadata needs to contain a name (either host- or group-name): {}".format(
                        env[ENV_META_KEY]))

            if env_type == ENV_TYPE_HOST:

                self.add_host(env_name, env.get(VARS_KEY, {}))

                if ENV_HOSTS_KEY in env.get(ENV_META_KEY, {}).keys():
                    raise NsblException(
                        "An environment of type {} can't contain the {} key".format(ENV_TYPE_HOST, ENV_HOSTS_KEY))

                for group in env[ENV_META_KEY].get(ENV_GROUPS_KEY, []):
                    self.add_host_to_group(env_name, group)

            elif env_type == ENV_TYPE_GROUP:

                self.add_group(env_name, env.get(VARS_KEY, {}))

                for host in env[ENV_META_KEY].get(ENV_HOSTS_KEY, []):
                    self.add_host_to_group(host, env_name)

                for group in env[ENV_META_KEY].get(ENV_GROUPS_KEY, []):
                    self.add_group_to_group(group, env_name)

            else:
                raise NsblException("Environment type needs to be either 'host' or 'group': {}".format(env_type))

            if TASKS_KEY in env.keys():
                self.tasks.append(NsblTasks(env, self.int_task_deskcs, self.role_repos, env_name))

        if "localhost" in self.hosts.keys() and "ansible_connection" not in self.hosts["localhost"].get(VARS_KEY,
                                                                                                        {}).keys():
            self.hosts["localhost"][VARS_KEY]["ansible_connection"] = "local"


    def list(self):
        """Lists all groups in the format that is required for ansible dynamic inventories.

        More info: https://docs.ansible.com/ansible/intro_dynamic_inventory.html, http://docs.ansible.com/ansible/dev_guide/developing_inventory.html

        Returns:
        dict: a dict containing all information about all hosts/groups
        """

        result = copy.copy(self.groups)
        result["_meta"] = {"hostvars": self.hosts}

        return json.dumps(result, sort_keys=4, indent=4)

    def host(self, host):
        """Returns the inventory information for the specified host, in the format required for ansible dynamic inventories.

        Args:
          host (str): the name of the host
        Returns:
        dict: all inventory information for this host
        """

        host_vars = self.hosts.get(host, {}).get(VARS_KEY, {})
        return json.dumps(host_vars, sort_keys=4, indent=4)

    def get_vars(self, env_name):
        """Returns all variables for the environment with the specified name.

        First tries whether the name matches a group, then tries hosts.

        Args:
          env_name (str): the name of the group or host
        Returns:
          dict: the variables for the environment
        """

        if env_name in self.groups.keys():
            return self.groups[env_name].get(VARS_KEY, {})
        elif env_name in self.hosts.keys():
            return self.hosts[env_name].get(VARS_KEY, {})
        else:
            raise NsblException("Neither group or host with name '{}' exists".format(env_name))

class NsblTaskProcessor(ConfigProcessor):
    """Processor to take a list of (unfrklized) tasks, and frklizes (expands) the data.

    In particular, this extracts roles and tags them with their types.
    """

    def validate_init(self):

        self.task_name_key = [TASKS_META_KEY, TASK_META_NAME_KEY]
        self.meta_roles = self.init_params['meta_roles']
        self.task_descs = self.init_params.get('task_descs', [])
        self.role_repos = self.init_params.get('role_repos', [])
        return True

    def process_current_config(self):

        new_config = self.current_input_config
        meta_task_name = new_config[TASKS_META_KEY][TASK_META_NAME_KEY]

        for task_desc in self.task_descs:
            task_desc_name = task_desc.get(TASKS_META_KEY, {}).get(TASK_META_NAME_KEY, None)

            if not task_desc_name == meta_task_name:
                continue

            new_config = dict_merge(task_desc, new_config, copy_dct=True)

        task_name = new_config.get(TASKS_META_KEY, {}).get(TASK_NAME_KEY, None)
        if not task_name:
            task_name = meta_task_name

        task_type = new_config.get(TASKS_META_KEY, {}).get(TASK_TYPE_KEY, None)
        roles = new_config.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {})
        task_roles = expand_external_role(roles, self.role_repos)

        int_role_path = get_internal_role_path(task_name, self.role_repos)
        if task_type == EXT_TASK_TYPE:
            if task_name not in roles.keys and task_name not in self.meta_roles.keys() and not int_role_path:
                    raise NsblException("Task name '{}' not found among role names, but task type is '{}'. This is invalid.".format(task_name, task_type))

        else:
            if task_name in task_roles.keys() or task_name in self.meta_roles.keys() or int_role_path:
                task_type = EXT_TASK_TYPE
            else:
                task_type = DYN_TASK_TYPE

            new_config[TASKS_META_KEY][TASK_TYPE_KEY] = task_type

        new_config[TASKS_META_KEY][TASK_NAME_KEY] = task_name
        new_config[TASKS_META_KEY][TASK_ROLES_KEY] = task_roles

        #TODO: use 'with_items' instead of this
        split_key = new_config[TASKS_META_KEY].get(SPLIT_KEY_KEY, None)
        if split_key:
            splitting = True
        else:
            splitting = False

        if splitting:
            if split_key and isinstance(split_key, string_types):
                split_key = split_key.split("/")

            split_value = new_config
            for split_token in split_key:
                if not isinstance(split_value, dict):
                    raise NsblException("Can't split config value using split key '{}': {}".format(split_key, new_config))
                split_value = split_value.get(split_token, None)
                if not split_value:
                    break

            if split_value and isinstance(split_value, (list, tuple)):

                for item in split_value:
                    item_new_config = copy.deepcopy(new_config)
                    temp = item_new_config
                    for token in split_key[:-1]:
                        temp = temp[token]

                    temp[split_key[-1]] = item

                    yield item_new_config

            else:
                yield new_config
        else:
            yield new_config


class NsblDynamicRoleProcessor(ConfigProcessor):
    """Processor to extract and pre-process single tasks to merge them into one or several roles later on."""

    def validate_init(self):
        self.id_role = 0
        self.current_tasks = []
        self.env_name = self.init_params["env_name"]
        return True

    def handles_last_call(self):

        return True

    def create_role_dict(self, tasks):

        task_vars = {}
        role_name = ["dyn_role"]
        roles = {}

        for idx, t in enumerate(tasks):
            task_id = "_dyn_role_task_{}".format(idx)
            role_name.append(t[TASKS_META_KEY][TASK_META_NAME_KEY])
            t[TASKS_META_KEY]["task_id"] = task_id
            roles.update(t[TASKS_META_KEY].get(TASK_ROLES_KEY, {}))
            for key, value in t.get(VARS_KEY, {}).items():
                task_vars["{}_{}".format(task_id, key)] = value

        dyn_role = {
            TASKS_META_KEY: {
                TASK_META_NAME_KEY: " ".join(role_name),
                TASK_NAME_KEY: "env_{}_dyn_role_{}".format(self.env_name, self.id_role),
                TASK_DYN_ROLE_DETAILS: copy.deepcopy(self.current_tasks),
                TASK_TYPE_KEY: DYN_ROLE_TYPE,
                TASK_ROLES_KEY: roles
            },
            VARS_KEY: task_vars}

        return dyn_role

    def process_current_config(self):


        if not self.last_call:
            new_config = self.current_input_config

            if new_config[TASKS_META_KEY][TASK_TYPE_KEY] == DYN_TASK_TYPE:
                self.current_tasks.append(new_config)
                yield None
            else:
                if len(self.current_tasks) > 0:
                    dyn_role = self.create_role_dict(self.current_tasks)
                    self.id_role = self.id_role + 1
                    self.current_tasks = []
                    yield dyn_role

                yield new_config
        else:
            if len(self.current_tasks) > 0:
                yield self.create_role_dict(self.current_tasks)
            else:
                yield None


class NsblTasks(object):

    def __init__(self, env, int_task_descs=[], role_repos=[], env_name="localhost"):

        self.env = env
        self.env_name = env_name
        self.role_repos = role_repos
        self.meta_roles = expand_external_role(env.get(TASKS_META_KEY, {}).get(TASK_ROLES_KEY, {}), self.role_repos)
        self.int_task_descs = int_task_descs

        # creating the expanded list of tasks
        nsbl_task_processor = NsblTaskProcessor({'env': self.env, 'task_descs': self.int_task_descs, 'meta_roles': self.meta_roles, 'role_repos': self.role_repos})

        # create the dynamic roles
        nsbl_dynrole_processor = NsblDynamicRoleProcessor({"env_name": self.env_name})

        id_processor = IdProcessor(NSBL_TASKS_ID_INIT)

        # otherwise each tasks inherits from the ones before
        temp_tasks = [[name] for name in self.env[TASKS_KEY]]

        frkl_format = generate_nsbl_tasks_format(int_task_descs)
        frkl_obj = Frkl(temp_tasks, [
            FrklProcessor(frkl_format),
            nsbl_task_processor, nsbl_dynrole_processor, id_processor])


        self.tasks = frkl_obj.process()


    def __repr__(self):

        return "NsblTasks(env_name='{}', no_tasks='{}')".format(self.env_name, len(self.tasks))

    def get_dict(self):

        temp = {}
        temp["env_name"] = self.env_name
        temp["tasks"] = self.tasks
        # temp["env"] = self.env

        return temp
